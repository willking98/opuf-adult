---
## Paper meta-information ##
title: "Development of a value-based scoring system for the WAItE using the OPUF in a sample of adults"
# shorttitle and shortauthors information will show in the header (not required)
shorttitle: "Valuation of the WAItE: OPUF"
shortauthors: King & Robinson
author:
  - name: Will King
    orcid: 0000-0000-0000-0000
    email: w.king2@newcastle.ac.uk
    attributes:
      corresponding: true
    affiliations:
      - id: uni
        name: Newcastle University
        department: Health Economics Group 
  - name: Tomos Robinson
    affiliations:
      - ref: uni
  - name: Angela Bate
    affiliations:
      - id: uni_northumbria
      - name: Northumbria University
      - department: Nursing, Midwifery & Health
  - name: Laura Ternent
    affiliations:
      - ref: uni
abstract: |
  Ipsum nostra facilisis sapien nullam. Facilisi himenaeos pharetra ultricies scelerisque non fusce quisque aliquam netus tellus. Dictum tellus et sociis quisque ornare ad a natoque magna blandit. Tortor duis aptent cursus lacus inceptos tristique magnis dictumst. Taciti varius nascetur aliquet hac ornare vitae ultricies. Rhoncus primis purus morbi aliquet quam cubilia nullam malesuada ridiculus.
keywords: [template, demo]

## Bibliography meta-information ##
reference-section-title: Bibliography  # adjust name of reference section
bibliography: bibliography.bib
# You an also use a local CSL file
# csl: diabetologia.csl
## Formats ##
format:
  aog-article-pdf: default
    # Set alternative fonts here
---

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
setwd("~/Dropbox/opuf-adult") # convert this to here for reproducibility
source("X_Run.R")
```

# Introduction {#sec-introduction}
This chapter presents the introduction, methods, results and discussion from an empirical study developing a utility value set for the WAItE using online personal utility functions (OPUF) with a representative sample of UK adults.  

## Compositional preference elicitation methods

Preference elicitation methods generally speaking, fall into two categories: compositional and decompositional [@Keeney1979DecisionsTrade-Offs; @Marsh2016MultipleForce; @Belton2002MultipleAnalysis]. That is, methods like DCE, BWS and TTO elicit preference orderings from individuals for an entire health state (composed of a combination of domains and levels) and then responses are decomposed to identify marginal contributions of each domain and level in each health state. Models like multinomial logit, mixed logit and latent class are frequently used to decompose responses to decompositional preference elicitation tasks [@Hauber2016StatisticalForce]. Coefficients estimated in these models form the basis of dis/utility values for each domain and level in a descriptive system. 

Conversely, compositional methods seek to identify preferences for each domain weighting and level rating individually for the number of domains and levels in a given descriptive system. Therefore, statistical models to elicit coefficients for each individual domain and level are not required and responses to each domain weighting and level rating are combined (in addition to an anchoring factor) to yield dis/utility values for each domain and level in the descriptive system. Compositional approaches can take many forms from simple VAS scores to using semantic categories and ranking methods [@BanaECosta1999TheApplication; @Danner2011IntegratingPreferences; @Oliveira2018ValuingStates]. These approaches have been used successfully in multi-criteria decision analysis (MCDA), but have been used less extensively in the preference elicitation space. Since the development of the OPUF, compositional approaches to elicit preferences have become more commonplace and a number of countries are using the OPUF to elicit value sets specific to their population [@Brodszky2023PCR108States]. 

## From PUF to OPUF
Personal utility functions were first used in the context of preference elicitation by Devlin et al. (2019) [@Devlin2019AFunctions] to estimate the feasibility for using this approach to estimate a value set for the EQ5D-5L. Since the feasibility for the underlying PUF methods were established, the approach has been expanded by Schneider and colleagues and converted into an online personal utility functions (OPUF) survey built initially using RShiny [@Schneider2022TheStates] and subsequently using Javascript (available \hyperlink{https://eq5d5l.me}{here}). Since the development of the OPUF, a number of descriptive systems and different research teams have begun utilising this method to elicit value sets [@Bray2024DevelopmentImpairment; @Brodszky2023PCR108States].  

## An overview of the OPUF structure
1. Domain weighting: This section is composed of two parts. First, domain ranking is completed where participants identify their most important domain. Second, respondents complete the domain weighting (swing weighting) where the relative importance of other domains is ascertained using their most important domain as a reference point. These questions are presented in Figure \ref{fig:domain weighting}. 
2. Level ratings: This element of the OPUF has varied across different iterations of the survey. Schnieder et al. (2022) [@Schneider2022TheStates] asked participants to rank the levels within the descriptive system generally (i.e. for any given domain), while other iterations have administered separate level rating questions for each domain in the descriptive system [@Bray2024DevelopmentImpairment]. Selection of method requires a trade-off between participant burden and sensitivity of level ratings to each domain. Figure \ref{fig:level rating} presents the level rating question for the pain/discomfort domain of the EQ5D-5L. 
3. Anchoring factor: A task is required to rescale the latent coefficients estimated via combining level ratings and domain weights onto the QALY scale. Participants are presented with a binary choice between the PITS state (or another state) of a given descriptive system and "being dead". If the PITS state is chosen, participants are asked to rank the PITS state on a VAS from 1 (full health) to 0 (dead). If "being dead" is chosen, participants are asked to rank "being dead" on a VAS from 1 (full health) to 0 (PITS state). Responses to these respective questions provide the anchoring factor. Anchoring questions, such that PITS is preferred to dead, are presented in Figure \ref{fig:anchoring factor}.

## OPUF logic and mathematics {#sec-OPUF_methods}
This section presents the logic and underlying mathematics required to convert the raw OPUF responses from one person into an anchored value set for the WAItE descriptive system. This example assumes that level ratings are obtained for each domain separately, therefore mathematics presented here differs to those presented elsewhere [@Schneider2022TheStates]. Example response data are used for demonstration in this section and are presented in Table \ref{tab:example_raw_OPUF}. 

\subsubsection{Example responses}
\begin{table}[ht]
\centering
\caption{Example individual responses to the OPUF}
\label{tab:example_raw_OPUF}
\footnotesize
\begin{tabular}{p{2cm} p{0.6cm} p{0.9cm} p{0.6cm} p{1.8cm} p{2cm} p{1.6cm} p{2.8cm}}
\toprule
& Tired & Walking & Sports & Concentration & Embarrassment & Unhappiness & Treated Differently \\
\midrule
Never          & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
Almost Never   & 14 & 26 & 21 & 15 & 16 & 12 & 19 \\
Sometimes      & 57 & 55 & 63 & 54 & 38 & 26 & 66 \\
Often          & 83 & 82 & 85 & 86 & 64 & 38 & 91 \\
Always         & 100 & 100 & 100 & 100 & 100 & 100 & 100 \\
\midrule
Domain Weighting & 28 & 33 & 36 & 45 & 100 & 34 & 56 \\
Normalised Weighting & 0.084 & 0.099 & 0.108 & 0.136 & 0.301 & 0.102 & 0.169 \\
\midrule
\multicolumn{8}{l}{WAItE PITS better than dead = Yes} \\
\multicolumn{8}{l}{Anchoring Task Response = 20} \\
\multicolumn{8}{l}{PITS Utility Value = 0.2} \\
\bottomrule
\end{tabular}
\end{table}

Level ratings (presented in Table \ref{tab:example_raw_OPUF})  are converted to coefficients bounded between 0-1 (shown in Equation \ref{eq:level_rescale}). Level rating coefficients are presented in Matrix \ref{level_matrix}. Attribute weights (presented in Table \ref{tab:example_raw_OPUF}) are then normalised to sum to the value of 1 by dividing each weight by the sum of all weights (shown in Equation \ref{eq:weight_normalise}). Normalised attribute weights are presented in Vector \ref{weight_vector}. 

\begin{equation}\label{eq:level_rescale}
    L_{ij} \cdot 0.01
\end{equation}

\begin{equation}\label{level_matrix}
L_{ij} = 
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.14 & 0.26 & 0.21 & 0.15 & 0.16 & 0.12 & 0.19 \\
0.57 & 0.55 & 0.63 & 0.54 & 0.38 & 0.26 & 0.66 \\
0.83 & 0.82 & 0.85 & 0.86 & 0.64 & 0.38 & 0.91 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 \\
\end{bmatrix}
\end{equation}
\\
\begin{equation}\label{eq:weight_normalise}
    \frac{w_{j}}{\sum{w_j}}
\end{equation}

\begin{equation}\label{weight_vector}
w_j = \begin{bmatrix}
    0.08& 0.10& 0.11& 0.14& 0.30& 0.10& 0.17
\end{bmatrix} 
\end{equation}
\\
%%%%%%%%%%% combining weights and levels 
Combining the attribute weights (Vector \ref{weight_vector}) with the level coefficients (Matrix \ref{level_matrix}) via element-wise multiplication (shown in Equation \ref{eq:element_wise_multiplication} gives the coefficient matrix presented in Matrix \ref{coeff_matrix}. Once the coefficient matrix has been estimated, preference values can be estimated on the 0-1 QALY scale where the worst health state (PITS state denoted 5555555) is zero and the best health state (denoted 1111111) is one. These latent coefficients must now be rescaled to incorporate the results from the PITS anchoring task so that the minimum utility value possible is equal to the PITS value. 


\begin{equation}\label{eq:element_wise_multiplication}
    L_{ij} \cdot  w_{j} = {\tilde{M}}_{ij}
\end{equation}

\begin{equation}\label{coeff_matrix}
\tilde{M}_{ij} =  
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.01 & 0.03 & 0.02 & 0.02 & 0.05 & 0.01 & 0.03 \\
0.05 & 0.05 & 0.07 & 0.07 & 0.11 & 0.03 & 0.11 \\
0.07 & 0.08 & 0.09 & 0.12 & 0.19 & 0.04 & 0.15 \\
0.08 & 0.10 & 0.11 & 0.14 & 0.30 & 0.10 & 0.17
\end{bmatrix}
\end{equation}
\\
To rescale the latent coefficient matrix to incorporate the anchoring task, the coefficient matrix is multiplied by the compliment of the PITS value (shown in Equation \ref{eq:anchoring}) to give the anchored coefficient matrix presented in Matrix \ref{ma:anchored_matrix}. 

\begin{equation}\label{eq:anchoring}
    \tilde{M}_{ij} \cdot (1-P) \quad \backepsilon \quad P = 0.2 
\end{equation}

\begin{equation}\label{ma:anchored_matrix}
\tilde{V}_{ij} =  
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.01 & 0.02 & 0.02 & 0.02 & 0.04 & 0.01 & 0.02 \\
0.04 & 0.04 & 0.06 & 0.06 & 0.09 & 0.02 & 0.09 \\
0.06 & 0.06 & 0.07 & 0.10 & 0.15 & 0.03 & 0.12 \\
0.06 & 0.08 & 0.09 & 0.11 & 0.24 & 0.08 & 0.14 \\
\end{bmatrix}
\end{equation}
\\

Once the attribute and level labels are reintroduced to the anchored coefficient matrix this forms the value set which presents the disutility corresponding to each attribute level combination presented in the WAItE. Table \ref{example valueset} presents the WAItE example PUF value set. Equations \ref{eq:HS1} present examples of how to estimate a utility value given a specific WAItE health state. 

\begin{table}[ht]
\centering
\caption{WAItE example PUF value set}
\label{example valueset}
\footnotesize
\begin{tabular}{p{2cm} p{0.6cm} p{0.9cm} p{0.6cm} p{1.8cm} p{2cm} p{1.6cm} p{2.8cm}}
\toprule
& Tired & Walking & Sports & Concentration & Embarrassment & Unhappiness & Treated Differently \\
\midrule
Never          & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
Almost Never   & 0.01 & 0.02 & 0.02 & 0.02 & 0.04 & 0.01 & 0.02 \\
Sometimes      & 0.04 & 0.04 & 0.06 & 0.06 & 0.09 & 0.02 & 0.09 \\
Often          & 0.06 & 0.06 & 0.07 & 0.10 & 0.15 & 0.03 & 0.12 \\
Always         & 0.06 & 0.08 & 0.09 & 0.11 & 0.24 & 0.08 & 0.14 \\
\bottomrule
\multicolumn{8}{l}{*Coefficients anchored by a PITS utility value of 0.2}
\end{tabular}
\end{table}

\begin{equation}\label{eq:HS1}
\begin{aligned}
    
    \text{Health State [5555555]} &\Rightarrow 1 - (0.06 + 0.08 + 0.09 + 0.11 + 0.24 + 0.08 + 0.14) = 0.20 
    
    \text{Health State [5223445]} &\Rightarrow 1 - (0.06 + 0.02 + 0.02 + 0.06 + 0.15 + 0.03 + 0.14) = 0.52
\end{aligned}
\end{equation}

%\begin{equation}\label{eq:HS2}
    %\text{Health State [2222222]} \Rightarrow 1 - (0.03 + 0.02 + 0.01 + 0.01 + 0.02 + 0.02 + 0.04) = 0.85
%\end{equation}

## Aggregation to social utility function
The OPUF is designed to be able to estimate personal utility functions and so estimation occurs on an individual basis. Aggregating personal utility functions to a social utility function (SUF) takes place by taking a mean of all the individual personal utility functions from your sample. This operation is presented in Equation \ref{eq:mean_valueset}. 

\begin{equation}\label{eq:mean_valueset}
\bar{V}_{{ij}} = \frac{\sum_{\tilde{V}_{{ij}}}^{}}{N}
\end{equation}  

# Methods
## Recruitment
This study recruited (n=300) adults to respond to a quality-of-life survey hosted online. Study participants were recruited based on specific quotas to form a representative sample based on UK census data. The survey was hosted on the \hyperlink{https://www.prolific.com}{Prolific} platform which invited paid respondents to complete the Weight-specific Adolescent Instrument for Economic evaluation (WAItE) version of the Online Personal Utility Functions (OPUF) survey. A demonstration of the OPUF survey and questions is available \hyperlink{https://survey.valorem.health/waite_opuf_adult2}{here}. Informed consent was obtained at the outset of the survey and participants reserved the right to withdraw at any point without giving a reason. Participants who withdrew were not paid and their data deleted. Participation in this survey was estimated to take approximately fifteen minutes to complete and participants received £2.50 as a payment upon completion. This is in line with reimbursements rates from other OPUF studies [@Schneider2022TheStates; @Bray2024DevelopmentImpairment] and is in line with recommended reimbursement rates from Prolific (\hyperlink{www.prolific.com}{www.prolific.com}). The survey was designed to be an unassisted survey administered online (no face-to-face contact) and no identifiable data was collected. Statistical analysis was conducted on the survey data. Newcastle University Medical School Ethics Committee approved this study (reference 49737/2023). The survey structure is detailed in [@sec-surveystructure]. 

## Survey structure {#sec-surveystructure}
1. Consent and Prolific ID: Participants were asked to consent to participate and enter their unique Prolific ID. This enables demographic information held by Prolific on their participants to be linked to each respondent. 
2. WAItE descriptive system: Participants were asked to complete the WAItE descriptive system (presented in Figure \ref{fig:waite_descriptive})to describe their current health state. 
3. Dimension selection}: Participants were presented with the worst level for each WAItE dimension and asked to choose which health problem would have the most negative impact on their quality of life. The dimension chosen is then used in the subsequent dimension swing weighting task.   
4. Dimension swing weighting: Participants were presented with each dimension in the WAItE and asked to consider an improvement from the worst level of that dimension to the best level of that dimension. Participants were asked to rank this improvement on a visual slider from 0-100 where the most important dimension (chosen in the previous task) is fixed at 100. Participants were reminded to use their most important dimension as a reference point.  
5. Level rating: Participants were presented with a specific dimension of the WAItE and shown each level within that dimension. Levels best and worst (never and always) were fixed at 0 and 100 respectively. Participants were asked to rank the intermediate levels within each dimension using the fixed levels as a reference point. 
6. Anchoring: Participants were presented with a binary choice asking whether they prefer the worst state of the WAItE (PITS state) or death. If participants choose the worst state of the WAItE, a second question is asked which asks them to rank the WAITE PITS state on a visual analogue scale where zero is labelled as being dead and one hundred is labelled as no health problems. If participants choose death in the binary choice, they were asked to rank being dead on a visual analogue scale where zero is labelled as the WAItE PITS state and one hundred is labelled as no health problems. 
7. Survey feedback and demographic questions: Participants were asked about how difficult they found the task to complete and demographic information on age, gender, ethnicity, education, employment and weight status.

## Live survey
```{=html}
<iframe width="800" height="600" src="https://survey.valorem.health/waite_opuf_adult2" title="Information"></iframe>
```



## Missing data
Through the survey design process the potential for large amounts of missing data has been mitigated by ensuring responses were compulsory to certain questions. However for ethical reasons, we allowed participants to not answer the questions relating to death. For participants who do not provide responses to the anchoring questions, their responses were imputed using multiple imputation by chained equations (MICE) [@White2011MultiplePractice] which were informed by demographic information and dimension weighting responses. 

## Preference heterogeneity
As personal utility function are estimated on an individual basis, exploring preference heterogeneity between individuals in the sample is straightforward. Investigating the heterogeneity of preferences between individuals, requires a measure of dis/similarity to quantify how far apart two PUFs are [@Schneider2024ExploringLevel]. The measurement and estimation of preference heterogeneity in this section will follow methods detailed by Schneider et al. (2024) [@Schneider2024ExploringLevel]. Each PUF estimated in this study was represented by a vector of 78,125 health state utility values for each respondent in the sample. In order to assess the dis/similarity between these PUFs, we used the euclidean difference measure (EUD). Analogous to a line between two points on a two dimensional plane, the EUD between two PUFs denotes the shortest path length in a 78,125 dimensional space. It is computed as the square root of the sum of the squared differences between the PUFs of individuals \(i\) and \(j\) (presented in Equation \ref{eq:EUD}). Once PUFs have been estimated for all individuals in the sample, pairwise EUD was estimated for all possible pairwise combinations within the sample. Pairwise EUD was stored in an [N \(\times\) N] distance matrix.   

\begin{equation} \label{eq:EUD}
  \begin{aligned}
    d_{EUD}(i,j) & =\sqrt{\sum_{}^{}(u_{i}(s_{1})-u_{j}(s_{1}))^{2}+ ... +(u_{i}(s_{78125})-u_{j}(s_{78125}))^{2}}\\
      & \backepsilon \quad \quad s = \{1111111, 2111111, ..., 5555555\}\\
  \end{aligned}
\end{equation}

## Permutational analysis of variance
Permutational analysis of variance (PERMANOVA), analogous to analysis of variance, is a geometric partitioning of variation across a multivariate data cloud, definied in the space of any given dissimilarity measure, in response to one or more groups [@Anderson2017; Anderson2013PERMANOVATesting]. This method of statistical testing has been used most commonly in ecological research to test for population dispersion among different subgroups [@Souza2013PopulationEstuary]. PERMANOVA decomposes the total distances between observations (SS\(_T\)) into within-groups (SS\(_W\)) and between groups sum-of-squares (SS\(_B\)). Equation \ref{eq:sumsquares} details the estimation of total and within-groups sum-of-squares. Mathematical notation presented here is reproduced from Schneider et al. (2024) [@Schneider2024ExploringLevel] for consistency.   

\begin{equation} \label{eq:sumsquares}
    SS_{T} = \frac{1}{N}\sum_{i=1}^{N-1}\sum_{j=i+1}^{N}d(i,j)^{2}; \quad SS_{W} = \sum_{i=1}^{N-1}\sum_{j=i+1}^{N}d(i,j)^{2}\epsilon_{ij}^{\ell}/n_{\ell}
\end{equation}

where N is the total sample size (=300), \(d(i,j)^2\) is the squared distance between the PUFs of participants \(i\) and \(j\), \(\epsilon_{i,j}\) indicator which is 1, if participants \(i\) and \(j\) belong to the same group, and 0 if they do not, and \(n_{\ell}\) is the size for group \(\ell\). Then, SS\(_B\) can then be calculated as SS\(_B\) = SS\(T\) – SS\(_W\), which allows calculating the pseudo F statistic for \(p\) groups:

\begin{equation}
    F= \frac{(\frac{SS_B}{p-1})}{(\frac{SS_W}{N-p})}
\end{equation}

Further details about the mathematical and statistical properties of PERMANOVA are available elsewhere [@Schneider2024ExploringLevel; Anderson2017; Anderson2013PERMANOVATesting]. In this study, we used PERMANOVA to explore the variability in WAItE health state preferences (individual value sets) between various subgroups. A multivariate PERMANOVA model was estimated with subgroups of: age, gender, self-reported weight status, education, employment status and ethncity.  

## Sensitivity analysis
In an experimental sensitivity analysis, preference heterogeneity was assessed using EUD estimated based on individual's personal utility functions anchored using the social PITS utility value (henceforth referred to as EUD2). This differed to prior preference heterogeneity estimation as individual variation in PITS utility values were not included in the EUD2 estimation. EUD2 was entirely composed by differences in level ratings and domain weights. Further details on the derivation of EUD2 are presented in Appendix \ref{app:EUD_derivation}. 

# Results
## Study participants
A sample of 334 individuals were approached to participate in the study via the survey company \hyperlink{https://www.prolific.com}{Prolific}. Individuals that successfully inputted their unique Prolific ID and obtained a correct completion code from the end of the study were included in the analysis sample and received a small payment (£2.50) for their participation. Seven participants were excluded from the study as they had an incorrect completion code and did not enter the correct unique Prolific ID. Therefore no data was available on those seven participants and so they were excluded from the analysis. An additional participant was excluded from the analysis due to completing the survey in eighteen seconds (well under the prespecified minimum time limit of 2 minutes). Two respondents timed-out while completing the survey and were therefore not included. Twenty-four individuals chose not complete the study (referred to by Prolific as `returned' participants). This left an analysis sample of N=300 participants who successfully completed the survey. A representative sample based on UK census data was obtained from Prolific. A summary of demographic information collected in the OPUF are presented in Table \ref{tab:demographicdataadultOPUF}.  


## Survey duration
The mean (SD) and median (IQR) survey completion time in minutes was 9.66 (5.85) and 8.15 (5.88; 11.89). @tbl-time summarises how much time was spent completing each individual section of the survey.

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# Time
# Convert start time from milliseconds to POSIXct
data$start_time <- as.POSIXct(data$timeTracker_surveyStartTime / 1000, origin = "1970-01-01", tz = "Europe/London")

data$start_time_minutes <- as.POSIXct(((data$timeTracker_surveyStartTime)/1000), origin="1970-01-01", tz="Europe/London")
data$time_taken_minutes <- as.numeric(as.POSIXct(((data$timeTracker_surveyEndTime)/1000), origin="1970-01-01", tz="Europe/London") - as.POSIXct(((data$timeTracker_surveyStartTime)/1000), origin="1970-01-01", tz="Europe/London"))

# Calculate time taken in seconds
data$time_taken <- as.numeric(
  as.POSIXct(data$timeTracker_surveyEndTime / 1000, origin = "1970-01-01", tz = "Europe/London") -
  as.POSIXct(data$timeTracker_surveyStartTime / 1000, origin = "1970-01-01", tz = "Europe/London"),
  units = "secs"
)

time_tab <- matrix(NA, nrow = 9, ncol = 5)
    
time_tab[1,] <- c(
  "WAItE",
  paste(round(mean(data$timeTracker_EPRO1_seconds), 1), " (", round(sd(data$timeTracker_EPRO1_seconds), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_EPRO1_seconds), 1), " (", round(quantile(data$timeTracker_EPRO1_seconds, 0.25), 1), "; ", round(quantile(data$timeTracker_EPRO1_seconds, 0.75), 1), ")", sep = ""),
  round(min(data$timeTracker_EPRO1_seconds), 1),
  round(max(data$timeTracker_EPRO1_seconds), 1)
)

time_tab[2,] <- c(
  "Dimension ranking",
  paste(round(mean(data$timeTracker_OPUFRanking1_seconds), 1), " (", round(sd(data$timeTracker_OPUFRanking1_seconds), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_OPUFRanking1_seconds), 1), " (", round(quantile(data$timeTracker_OPUFRanking1_seconds, 0.25), 1), "; ", round(quantile(data$timeTracker_OPUFRanking1_seconds, 0.75), 1), ")", sep = ""),
  round(min(data$timeTracker_OPUFRanking1_seconds), 1),
  round(max(data$timeTracker_OPUFRanking1_seconds), 1)
)

time_tab[3,] <- c(
  "Dimension weighting",
  paste(round(mean(data$timeTracker_OPUFSwingWeight1_seconds), 1), " (", round(sd(data$timeTracker_OPUFSwingWeight1_seconds), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_OPUFSwingWeight1_seconds), 1), " (", round(quantile(data$timeTracker_OPUFSwingWeight1_seconds, 0.25), 1), "; ", round(quantile(data$timeTracker_OPUFSwingWeight1_seconds, 0.75), 1), ")", sep = ""),
  round(min(data$timeTracker_OPUFSwingWeight1_seconds), 1),
  round(max(data$timeTracker_OPUFSwingWeight1_seconds), 1)
)

time_tab[4,] <- c(
  "Level rating",
  paste(round(mean(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), " (", round(sd(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), " (", round(quantile(data$timeTracker_OPUFLevelRating_seconds, 0.25, na.rm=T), 1), "; ", round(quantile(data$timeTracker_OPUFLevelRating_seconds, 0.75, na.rm=T), 1), ")", sep = ""),
  round(min(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1),
  round(max(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1)
)

time_tab[5,] <- c(
  "PITS vs death",
  paste(round(mean(data$timeTracker_OPUFDeadChoice_seconds), 1), " (", round(sd(data$timeTracker_OPUFDeadChoice_seconds), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_OPUFDeadChoice_seconds), 1), " (", round(quantile(data$timeTracker_OPUFDeadChoice_seconds, 0.25), 1), "; ", round(quantile(data$timeTracker_OPUFDeadChoice_seconds, 0.75), 1), ")", sep = ""),
  round(min(data$timeTracker_OPUFDeadChoice_seconds), 1),
  round(max(data$timeTracker_OPUFDeadChoice_seconds), 1)
)

time_tab[6,] <- c(
  "PITS-VAS",
  paste(round(mean(data$timeTracker_OPUFVasAnchoring_seconds), 1), " (", round(sd(data$timeTracker_OPUFVasAnchoring_seconds), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_OPUFVasAnchoring_seconds), 1), " (", round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.25), 1), "; ", round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.75), 1), ")", sep = ""),
  round(min(data$timeTracker_OPUFVasAnchoring_seconds), 1),
  round(max(data$timeTracker_OPUFVasAnchoring_seconds), 1)
)

time_tab[7,] <- c(
  "PITS-VAS",
  paste(round(mean(data$timeTracker_OPUFVasAnchoring_seconds), 1), " (", round(sd(data$timeTracker_OPUFVasAnchoring_seconds), 1), ")", sep = ""),
  paste(round(median(data$timeTracker_OPUFVasAnchoring_seconds), 1), " (", round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.25), 1), "; ", round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.75), 1), ")", sep = ""),
  round(min(data$timeTracker_OPUFVasAnchoring_seconds), 1),
  round(max(data$timeTracker_OPUFVasAnchoring_seconds), 1)
)

time_tab[8,] <- c(
  "Total (secs)",
  paste(round(mean(data$time_taken), 1), " (", round(sd(data$time_taken), 1), ")", sep = ""),
  paste(round(median(data$time_taken), 1), " (", round(quantile(data$time_taken, 0.25), 1), "; ", round(quantile(data$time_taken, 0.75), 1), ")", sep = ""),
  round(min(data$time_taken), 1),
  round(max(data$time_taken), 1)
)

time_tab[9,] <- c(
  "Total (mins)",
  paste(round(mean(data$time_taken_minutes), 2), " (", round(sd(data$time_taken_minutes), 2), ")", sep = ""),
  paste(round(median(data$time_taken_minutes), 2), " (", round(quantile(data$time_taken_minutes, 0.25), 2), "; ", round(quantile(data$time_taken_minutes, 0.75), 2), ")", sep = ""),
  round(min(data$time_taken_minutes), 2),
  round(max(data$time_taken_minutes), 2)
)

# Optionally, set the column names
colnames(time_tab) <- c("Section", "Mean (SD)", "Median (Q1; Q3)", "Min", "Max")  # adjusted the column name


```
```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-time
#| tbl-cap: Survey completion times (secs)
kable(time_tab, digits = 3)

```

## WAItE descriptive system
Responses to the WAItE descriptive system are presented in Table \ref{tab:demographicdataadultOPUF}. Feeling tired and avoiding doing sport were the domains that were most frequently experienced by participants in our analysis sample. WAItE summary statistics were in line with results from previous studies [@Robinson2019EstimatingEvaluation].

\begin{table}[h] 
\caption{Summary of demographic data collected in the OPUF}
\label{tab:demographicdataadultOPUF}
\centering
\begingroup\small
\begin{tabular}{p{12cm} r{3cm}}
\toprule
\textbf{Participant characteristics (N=300)} & \textbf{N (\%)} \\
  \hline
\textbf{Age} &  \\
  \quad 18-24 & 32 (10.9\%) \\ 
  \quad 25-34 & 50 (17\%) \\ 
  \quad 35-44 & 48 (16.3\%) \\ 
  \quad 45-54 & 49 (16.7\%) \\ 
  \quad 55-64 & 81 (27.6\%) \\ 
  \quad 65-90 & 34 (11.6\%) \\
  \quad Not Stated & 6 (2.0\%) \\
  \textbf{Gender} & \\
  \quad Female & 154 (51\%) \\
  \quad Male & 144 (48\%) \\
  \quad Non-binary & 1 (0\%) \\
  \textbf{Ethnicity} & \\
  \quad White & 251 (84\%) \\
  \quad Asian & 23 (8\%) \\
  \quad Black & 11 (4\%) \\
  \quad Mixed & 10 (3\%) \\
  \quad Other & 5 (2\%) \\
  \textbf{Weight Status} & \\
  \quad Normal & 154 (51\%) \\
  \quad Overweight & 104 (35\%) \\
  \quad Obese & 30 (10\%) \\
  \quad Underweight & 8 (3\%) \\
  \quad Prefer not to say & 4 (1\%) \\
  \textbf{Education} & \\
  \quad Degree & 147 (49\%) \\
  \quad A Level & 64 (21\%) \\
  \quad Higher Education & 46 (15\%) \\
  \quad Other & 20 (7\%) \\
  \quad GCSE A-C & 18 (6\%) \\
  \quad GCSE D-G & 5 (2\%) \\
  \textbf{Occupation} & \\
  \quad Full-time & 130 (43\%) \\
  \quad Part-time & 62 (21\%) \\
  \quad Not Paid & 30 (10\%) \\
  \quad Other & 31 (10\%) \\
  \quad Student & 17 (6\%) \\
  \quad Unemployed & 18 (6\%) \\
  \quad Not Stated & 9 (3\%) \\
  \quad Starting a New Job & 3 (1\%) \\
   \textbf{WAItE} & Mean (SD) \\
   \quad Tiredness & 3.4 (0.8) \\
   \quad Walking & 2.1 (1.1) \\
   \quad Sport & 3.3 (1.3) \\
   \quad Concentration & 2.7 (1.0) \\
   \quad Embarrassment & 2.2 (1.2) \\
   \quad Unhappiness & 2.3 (1.0) \\
   \quad Treated differently & 1.9 (0.9) \\
   \quad \textbf{Total} & 17.8 (4.8) \\
   \bottomrule
\end{tabular}
\endgroup
\end{table}








## Level ratings
Level ratings are presented individually for each different domain in @tbl-level. The best and worst levels (\textit{Always} and \textit{Never}) were fixed at 0 and 100 respectively. The second best level (\textit{Almost never}) had the lowest VAS score in the Sports and Embarrassment domain, while the second worst level (\textit{Often}) had the highest VAS score in the Concentration domain. In this question, higher VAS scores indicate worse states of health.


```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
# kable(anchored_matrix, digits = 3)
```
```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# Initialize the level_tab matrix
level_tab <- matrix(NA, nrow = 21, ncol = 5)

# List of categories
categories <- c("tired", "walk", "sports", "concentration", "embarrassment", "unhappiness", "treat")

# Fill the matrix using loops
row_index <- 1
for (category in categories) {
  for (i in 1:3) {
    level_tab[row_index, ] <- c(c("Almost never", "Sometimes", "Often")[i], calculate_stats(data[[paste0("opuf_levelRatings_", category, "_", i)]]))
    row_index <- row_index + 1
  }
}

colnames(level_tab) <- colnames(time_tab)

```
```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-level
#| tbl-cap: Summary of OPUF level ratings by domain
kable(level_tab, digits = 3)
```


## Domain weights
Summary statistics of domain weightings are presented in @tbl-domain. On average, Tiredness (76.5) and Unhappiness (70) were considered to be more important to participants than Embarrassment (40.1) and Sports (42.3). There was less variability in domain weighting responses to Tiredness than responses to Treated differently or Embarrassment.     %TODO: Add relative attribute importance section with normalised RAI score







```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# domain weighting table
domain_tab <- matrix(NA, nrow = 13, ncol = 5)
domain_tab[1,] <- c("Tired", calculate_stats(data$opuf_swingWeights_tired))
domain_tab[2,] <- c("Walking", calculate_stats(data$opuf_swingWeights_walk))
domain_tab[3,] <- c("Sports", calculate_stats(data$opuf_swingWeights_sports))
domain_tab[4,] <- c("Concentration", calculate_stats(data$opuf_swingWeights_concentration))
domain_tab[5,] <- c("Embarrassment", calculate_stats(data$opuf_swingWeights_embarrassment))
domain_tab[6,] <- c("Unhappiness", calculate_stats(data$opuf_swingWeights_unhappiness))
domain_tab[7,] <- c("Treated differently", calculate_stats(data$opuf_swingWeights_treat))

# fix anchorpoint data
data$preferred_pits[data$opuf_anchorPoint==""] <- NA
data$preferred_pits[data$opuf_anchorPoint=="dead"] <- 1
data$preferred_pits[data$opuf_anchorPoint=="pits"] <- 0
preferred_pits <- data$preferred_pits[!is.na(data$preferred_pits)]

pits_vas <- ifelse(data$opuf_anchorPoint=="dead", data$opuf_anchorVal, NA)
pits_vas <- pits_vas[!is.na(pits_vas)]
dead_vas <- ifelse(data$opuf_anchorPoint=="pits", data$opuf_anchorVal, NA)
dead_vas <- dead_vas[!is.na(dead_vas)]
opuf_pitsUtility <- data$opuf_pitsUtility
opuf_pitsUtility <- opuf_pitsUtility[!is.na(opuf_pitsUtility)]
censored_opuf_pitsUtility <- ifelse(opuf_pitsUtility < -1, -1, opuf_pitsUtility) 


domain_tab[8,] <- c("PITS preferred to death", calculate_stats(preferred_pits))
domain_tab[9,] <- c("PITS-VAS", calculate_stats(pits_vas))
domain_tab[10,] <- c("Dead-VAS", calculate_stats(dead_vas))
domain_tab[11,] <- c("PITS VAS uncensored", calculate_stats(opuf_pitsUtility))
domain_tab[12,] <- c("PITS VAS censored", calculate_stats(censored_opuf_pitsUtility))

domain_tab[13,] <- c("PITS Utility Value", calculate_stats(data$PITS))

colnames(domain_tab) <- colnames(time_tab)
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-domain
#| tbl-cap: Summary of OPUF domain weights and anchoring responses
kable(domain_tab, digits = 3)
```
## Anchoring
The majority of respondents in the sample preferred the WAItE PITS state to being dead (87\%). Therefore, 13\% of participants answered the dead-VAS and 87\% answered the PITS-VAS. A proportion of participants did not answer the anchoring task (1.67\%). After winsorizing extreme values (top and bottom 0.1\%) [@2003ApplyingTechniques] and conducting multiple imputation by chained equations on the missing values, the mean (SD) and median (IQR) PITS utility value was 0.282 (1.456) and 0.5 (0.6). The distribution of WAItE PITS utility values (after winsorizing and imputation) is presented in @fig-hist.

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
hist <- filter(data, PITS>-5.01)
hist <- ggplot(hist, aes(x = PITS, fill = PITS < -0.05)) +
  geom_histogram(binwidth = 0.15, color = "black", alpha = 0.9) +
  scale_fill_manual(values = c("FALSE" = "#f2db0d", "TRUE" = "#625e5e"), 
                    labels = c("FALSE" = "PITS-VAS", "TRUE" = "Dead-VAS"),
                    name = "Anchoring task") +
  labs(x = "WAItE PITS utility",
       y = "Frequency") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.2, face = "bold", size = 14),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    legend.text = element_text(size = 12)
  ) +
  theme(
    axis.title.x = element_text(size = 14, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size = 14, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    
  )
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: fig-hist
#| fig-cap: Distribution of PITS utility values
plot(hist)
```


## Social utility function estimation
Personal utility functions were estimated individually for each participant in our analysis sample via methods outlined in @sec-OPUF_methods. After this, individual PUFs were aggregated into a group utility function and anchored using the group PITS utility value (0.282) to give the social utility function. Descriptive statistics from the social utility function are presented in @tbl-suf whereby the mean values can be used to estimate utility values for WAItE health states. 



```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# Bootstrapping 
#############################################################################
#setseed
#############################################################################
#setseed
set.seed(1998)
# Set the number of bootstrap iterations
n_iterations <- 10000

# Initialize a list to store the mean matrices from each bootstrap iteration
bootstrap_means <- list()
bootstrap_medians <- list()

if (method == "median") {
  for (n in 1:n_iterations) {
    # Sample with replacement from the results_list
    sample_indices <- sample(1:length(results_list), replace = TRUE)
    bootstrap_sample <- results_list[sample_indices]

    # Initialize a matrix to store the sum of the bootstrap sample matrices
    bootstrap_median_matrix <- matrix(0, nrow = 7, ncol = 4)  
    #TODO: Above code was previously nrow = 7, ncol = 4??? Figure out why
    attributes <- c("tired", "walking", "sports", "concentration", "embarrassed", "unhappiness", "treat")
    levels <- 2:5

    # Populate medians for each attribute and level in a single matrix
    median_matrix <- do.call(cbind, lapply(seq_along(attributes), function(j) {
      medians <- sapply(levels, function(lvl) median(sapply(bootstrap_sample, function(mat) mat[lvl, j])))
      c(0, medians)  # Add 0 at the start for each attribute
    }))

    # bootstrap_median_matrices <- c(bootstrap_median_matrices, median_matrix) 
    #
    # # Calculate the median matrix for this bootstrap sample
    # bootstrap_median_matrix <- bootstrap_sum_matrix / length(bootstrap_sample)
    # Anchor it
    bootstrap_median_matrix <- median_matrix * (1-anchor) 

    # Store the bootstrap mean matrix
    bootstrap_medians[[n]] <- bootstrap_median_matrix
  }
}

if (method == "mean"){
  # Bootstrap loop
  for (n in 1:n_iterations) {
    # Sample with replacement from the results_list
    sample_indices <- sample(1:length(results_list), replace = TRUE)
    bootstrap_sample <- results_list[sample_indices]

    # Initialize a matrix to store the sum of the bootstrap sample matrices
    bootstrap_sum_matrix <- matrix(0, nrow = 7, ncol = 4)  
    #TODO: Above code was previously nrow = 7, ncol = 4??? Figure out why

    # Sum all matrices in the bootstrap sample
    for (m in bootstrap_sample) {
      m <- m[-1,]
      m <- t(m)
      bootstrap_sum_matrix <- bootstrap_sum_matrix + m
    }

    # Calculate the mean matrix for this bootstrap sample
    bootstrap_mean_matrix <- bootstrap_sum_matrix / length(bootstrap_sample)
    # Anchor it
    bootstrap_mean_matrix <- bootstrap_mean_matrix * (1-anchor) 

    # Store the bootstrap mean matrix
    bootstrap_means[[n]] <- bootstrap_mean_matrix
  }
}
# Convert the list of bootstrap mean matrices into a 3D array
bootstrap_array <- simplify2array(bootstrap_means)
if (method == "median"){
  bootstrap_array <- simplify2array(bootstrap_means)
}
# Initialize matrices to store the required statistics
mean_matrix <- apply(bootstrap_array, c(1, 2), mean)
median_matrix <- apply(bootstrap_array, c(1, 2), median)
q1_matrix <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.25)
q3_matrix <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.75)
min_matrix <- apply(bootstrap_array, c(1, 2), min)
max_matrix <- apply(bootstrap_array, c(1, 2), max)

# Calculate 95% confidence intervals
ci_lower <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.025)
ci_upper <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.975)

# Initialize an empty list to store each row of the final table
final_table <- list()

# Define the domain names and the levels
domains <- c("tired", "walk", "sports", "concentrate", "embarrassment", "unhappiness", "treated differently")
levels <- c("almost never", "sometimes", "often", "always")

# Iterate through the rows and columns of the matrices
for (i in 1:nrow(mean_matrix)) {
  for (j in 1:ncol(mean_matrix)) {
    row_label <- paste0(domains[i], ", ", levels[j])
    mean_ci <- paste0(round(mean_matrix[i, j], 3), " (", round(ci_lower[i, j], 3), "; ", round(ci_upper[i, j], 3), ")")
    median_q1_q3 <- paste0(round(median_matrix[i, j], 3), " (", round(q1_matrix[i, j], 3), "; ", round(q3_matrix[i, j], 3), ")")
    min_val <- round(min_matrix[i, j], 3)
    max_val <- round(max_matrix[i, j], 3)
    
    final_table[[length(final_table) + 1]] <- c(row_label, mean_ci, median_q1_q3, min_val, max_val)
  }
}

# Convert the final_table list to a data frame
final_df <- as.data.frame(do.call(rbind, final_table), stringsAsFactors = FALSE)
colnames(final_df) <- c("Dimension Level", "Mean (95% CI)", "Median (Q1; Q3)", "Min", "Max")

#TODO: IMPORTANT resolve the medians and Qs to be actual not bootstrapped

```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-suf
#| tbl-cap: Social utility function based on 300 PUFs
kable(final_df)
```

@fig-sufplain presents the mean social utility function (thick line) alongside individual personal utility functions (thin lines) for a selection of 100 WAItE health states ordered from high to low utility according to the social preference. Deviations of individual utility functions from the social preference illustrate the heterogeneity of preference within our analysis sample. Individual personal utility functions shown in @fig-sufplain are anchored using individual PITS utility values rather than the social PITS utility value.   

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: fig-sufplain
#| fig-cap: Social and individual utility functions
plot(plain_chart)
```

## Preference heterogeneity
After estimating individual PUFs for all participants, pairwise EUD was estimated between all participants. This yielded a [300 \(\times\) 300] distance matrix with 44,850 unique pairwise comparisons. The mean (SD) and median (IQR) EUD were 47.60 (19.40) and 44.81 (34.06; 57.40). The highest and lowest observed EUD were 189.16 and 0. @fig-eud illustrates the relationship between EUD and WAItE health states. EUD tends to increase as WAItE health states worsen. That is, as the severity of WAItE health states increases, the more heterogeneous preferences become among our sample. 

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: fig-eud
#| fig-cap: Social and individual utility functions coloured by EUD
plot(eud_chart)
```

\subsection{PERMANOVA}
@tbl-permanova presents the PERMANOVA model results. Presented are within‐group sum‐of‐squares (SS\(_W\)) for each group individually and for all groups combined, and the corresponding R\(^2\), pseudo \(F\), and \(p\) values. Preference heterogeneity was significantly affected by age (\(p\) = 0.03), though the amount of variability in preferences that could be explained by age was relatively small (R\(^2\)=5.7\%). @fig-age presents the difference in preferences between different age groups. Generally, as age increases, health state utility values for each given WAItE health state are higher. That is, younger populations tend to place more disutility on WAItE health problems than older populations. While weight status was not significantly related to preference heterogeneity according to the PERMANOVA model, given the WAItE is a weight-specific measure, it was informative to explore the relationship between preferences and weight status. Though not statistically significant, we can observe a difference in preferences between normal weight and overweight individuals in @fig-weight. For a given WAItE health state, overweight individuals in our sample placed less disutility on that state than did normal weight individuals. 


```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-permanova
#| tbl-cap: Results of PERMANOVA – testing for differences in WAItE health state preferences between group characteristics
kable(permanova_main, digits = 3)
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: fig-age
#| fig-cap: Social and individual utility functions grouped by age status
plot(age_chart)
```
## Sensitivity analysis
EUD2 was estimated for each pairwise comparison of individuals in our study. This yielded a [300 \(\times\) 300] distance matrix with 44,850 unique pairwise comparisons. The mean (SD) and median (IQR) EUD were 34.30 (13.82) and 32.25 (24.54; 41.27). Results from the PERMANOVA2 analysis are presented in @tbl-permanova2. After exclusion of individual variation in anchoring responses, weight status and age had a significant impact upon heterogeneity within our sample; though the amount of heterogeneity that was explained by these variables was fairly small (4.9\%). 

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-permanova2
#| tbl-cap: Results of PERMANOVA2 – testing for differences in level rating and domain weighting preferences between group characteristics
kable(permanova_main, digits = 3)
```

# Discussion
This study is the first time that the OPUF has been used to estimate health state utility values for the WAItE. We obtained a representative sample of high quality data from Prolific, a survey company known for their high quality respondents [@Peer2022DataResearch]. Our average domain weightings and implied ordering were similar to those exhibited in Robinson et al. (XX VIH). 

Anchoring of the WAItE PITS state was a difficult procedure that required a number of methodological decisions. We decided to use uncensored responses to the Dead-VAS task which meant that data from one respondent (-99) skewed the mean PITS utility value quite substantially. To mitigate the impact of extreme values on the mean, we conducted winsorization of values lying in the outer 0.1\% of the distribution. This practice, while effective at limiting the influence of extreme values on the mean, could understate the genuine variability in the data. Though, it is likely that exclusion of this participant would have had a more detrimental effect to presenting the genuine variability of responses. 

The social utility function elicited through this study, and underlying utility value set, present monotonic preferences which behave as we would have expected ex-ante (based on qualitative piloting work). Tiredness and Unhappiness were considered the most important domains while Embarrassment and Sports the least. This finding concurs with qualitative work conducted prior and also is in accordance with previous valuation work done with the WAItE (XX VIH). Prior valuation work, which used a DCE to elicit preferences, yielded latent coefficients which violated the rational choice axiom of monotonicity. In the OPUF, monotonicity is somewhat forced through the choice architecture of the level rating and through the additional prompt to reconsider responses that are not monotonic. Forced monotonicity, in this context, could be problematic for eliciting unbiased preferences if preferences for certain health states are truly not monotonic. For example, prior qualitative work has suggested that "I almost never get tired" might be preferable to "I never get tired" in some circumstances where respondents are thinking about experiencing insomnia and sleep quality. This being said, the WAItE descriptive system was designed to be a monotonic descriptive system, validated using Rasch analysis, and so having a monotonic utility value set makes logical sense. 

Preferences elicited through this study were considerably heterogeneous. This can be understood through the mean EUD value (47.6) but also illustrated in @fig-sufplain through the deviations of individual PUFs from the social utility function. Following on from prior work [@Schneider2024ExploringLevel], we estimated EUD by calculating a distance matrix between each pairwise comparison of individual value sets for all 78125 WAItE health states. The implication of estimating distance (preference heterogeneity) by using individual value sets allows for much of the preference heterogeneity that exists to be composed of differences in individual anchoring values (PITS state responses) rather than differences in level ratings and domain weightings. This methodological decision, ultimately, results in the majority of EUD being composed of differences in anchoring values and this finding is important to acknowledge. Anchoring differences are important to present and explore, though in this preference heterogeneity analysis could be drowning out the heterogeneity in level ratings and domain weighting. An example of this can be shown through the age preference heterogeneity in @fig-age. Preference heterogeneity is evident between individuals above and below age 35 and if we consider the mean PITS values for those two subgroups (age \(<\) 35 = -0.281; age \(>\) 34 = 0.487) we can see that a clear difference in anchoring responses is evident. 

A methodological exploration was conducted as a sensitivity analysis to limit the influence that anchoring variation has on the overall preference heterogeneity. We considered this to be a strength of the research as it offers a new approach to decompose preference heterogeneity into anchoring variation and the difference in level ratings and domain weightings. After exclusion of individual variation in anchoring responses, weight status and age were found to have a significant impact on preference heterogeneity within our sample; though the amount of variation that could be explained was limited. Preference heterogeneity between those of normal weight and those who were overweight is illustrated in Figure @fig-weight.

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: fig-weight
#| fig-cap: Social and individual utility functions grouped by weight status
plot(weight_chart)
```
This method of estimating preference heterogeneity should not be considered the gold standard, as only part of the variation in preferences is explored here. It can however be considered an additional option for future researchers that wish to isolate the effect of anchoring responses on overall preference heterogeneity. It is also, to our knowledge, the first time preference heterogeneity has been decomposed in this way with the OPUF. 

The value set estimated here offers an alternative choice of preference values to the existing value sets estimated using DCE (shown in Figure \ref{tab:WAITE val sets}). When comparing the anchored coefficients between value sets, one of the key areas of divergence is where levels have been collapsed in the DCE value set. In the OPUF, "I almost never get tired" is given 0.029 compared to 0.064 in the DCE due to collapsing levels. Generally the difference between coefficients that have not been `collapsed' between the value sets is small suggesting that there is comparability to an extent between the value sets. Anchoring values were broadly similar between studies too. The mean PITS utility values between studies were broadly comparable with a maximum range of 0.059. Interestingly, the EQ-VAS anchoring task mean (0.289) was remarkably similar to the OPUF VAS anchoring task mean (0.282) again supporting the use of VAS for elicitation of PITS utility values. 

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#TODO: Add final table comparing valuesets
# kable(permanova_main)
```




