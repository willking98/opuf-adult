legend.position="none",
plot.title = element_text(size=14),
panel.grid = element_blank(),
axis.text = element_blank(),
legend.margin=unit(0, "null")
) +
xlab("") +
ylab("")
}
plot_pie(data1, c(10,35,55,75,93))
# Libraries
library(tidyverse)
library(hrbrthemes)
library(viridis)
library(patchwork)
# create 3 data frame:
data1 <- data.frame( name=letters[1:5], value=c(17,18,20,22,24) )
data2 <- data.frame( name=letters[1:5], value=c(20,18,21,20,20) )
data3 <- data.frame( name=letters[1:5], value=c(24,23,21,19,18) )
# Plot
plot_pie <- function(data, vec){
ggplot(data, aes(x="name", y=value, fill=name)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start=0, direction = -1) +
scale_fill_viridis(discrete = TRUE,  direction=-1) +
geom_text(aes(y = vec, label = rev(name), size=4, color=c( "white", rep("black", 4)))) +
scale_color_manual(values=c("black", "white")) +
theme_ipsum() +
theme(
legend.position="none",
plot.title = element_text(size=14),
panel.grid = element_blank(),
axis.text = element_blank(),
legend.margin=unit(0, "null")
) +
xlab("") +
ylab("")
}
plot_pie(data1, c(10,35,55,75,93))
# Analysis of preferred choice task
# Install dependencies
library(tidyverse)
# Read in the data
AP1 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/AP1_PCT.csv")
AP2 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/AP2_PCT.csv")
AP3 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/AP3_PCT.csv")
AP4 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/AP4_PCT.csv")
AP5 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/AP5_PCT.csv")
YP1 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/YP1_PCT.csv")
YP2 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/YP2_PCT.csv")
YP3 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/YP3_PCT.csv")
YP4 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/YP4_PCT.csv")
YP5 <- read.csv("C:/Users/b6037482/OneDrive - Newcastle University/PhD/2. TA/Pilot/Results/YP5_PCT.csv")
# Merge data
data <- full_join(AP1, AP2)
data <- full_join(data, AP3)
data <- full_join(data, AP4)
data <- full_join(data, AP5)
data <- data %>% mutate(Adult = 1)
data
load("C:\\Users\\b6037482\\OneDrive - Newcastle University\\PhD\\3. VS\\OPUF Adult\\permanovaworkspace.RData")
permanova_main <- adonis2(distance_vector ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
library(vegan)
permanova_main <- adonis2(distance_vector2 ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
print(permanova_main)
load("C:\\Users\\b6037482\\OneDrive - Newcastle University\\PhD\\3. VS\\OPUF Adult\\permanovaworkspace.RData")
permanova_main <- adonis2(distance_vector2 ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
print(permanova_main)
load("C:\\Users\\b6037482\\OneDrive - Newcastle University\\PhD\\3. VS\\OPUF Adult\\permanovaworkspace.RData")
permanova_main <- adonis2(distance_vector2 ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
print(permanova_main)
permanova_main <- adonis2(distance_vector ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
print(permanova_main)
load("C:\\Users\\b6037482\\OneDrive - Newcastle University\\PhD\\3. VS\\OPUF Adult\\permanovaworkspace.RData")
permanova_main <- adonis2(distance_vector2 ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
print(permanova_main)
permanova_main <- adonis2(distance_vector ~ age_factor + weightdata + educationdata + occupationdata + genderdata + ethnicitydata, permutations = 10000)
print(permanova_main)
install.packages("idefix")
# Install and load the idefix package
library(idefix)
# Define attributes and levels
n_attributes <- 7
n_levels <- 5
levels_per_attribute <- rep(n_levels, n_attributes)
# Create an initial random design
n_choice_sets <- 20  # Number of choice sets
n_alternatives <- 2  # Number of alternatives per set
initial_design <- example_design(levels_per_attribute, n_sets = n_choice_sets, n_alts = n_alternatives)
# Define priors (assuming null priors)
priors <- rep(0, sum(levels_per_attribute) - n_attributes)
# Optimize the design for D-efficiency
d_eff_design <- Dopt.design(cand.set = initial_design,
n_sets = n_choice_sets,
n_alts = n_alternatives,
prior = priors,
n.draws = 1000)
# Check D-efficiency
d_eff <- Defficiency(d_eff_design$design)
print(d_eff)
# View the final design
print(d_eff_design$design)
initial_design <- example_design(levels_per_attribute, n_sets = n_choice_sets, n_alts = n_alternatives)
library(idefix)
# Define attributes and levels
n_attributes <- 7
n_levels <- 5
levels_per_attribute <- rep(n_levels, n_attributes)
# Generate the full factorial candidate set
candidate_set <- Profiles(lvls = levels_per_attribute)
candidate_set <- Profiles(lvls = levels_per_attribute, coding = rep("D", n_attributes))
# Define number of choice sets and alternatives
n_choice_sets <- 20  # Number of choice sets
n_alternatives <- 2  # Number of alternatives per set
# Generate an initial random design
initial_design <- Modfed(cand.set = candidate_set,
n.sets = n_choice_sets,
n.alts = n_alternatives,
alt.cte = FALSE)
n_attributes <- 7
n_levels <- 5
levels_per_attribute <- rep(n_levels, n_attributes)
# Generate the full factorial candidate set with dummy coding
candidate_set <- Profiles(lvls = levels_per_attribute, coding = rep("D", n_attributes))
# Generate random parameter draws (assuming normal distribution)
n_draws <- 1000  # Number of draws
par.draws <- MASS::mvrnorm(n = n_draws, mu = rep(0, sum(levels_per_attribute) - n_attributes), Sigma = diag(1, sum(levels_per_attribute) - n_attributes))
# Define number of choice sets and alternatives
n_choice_sets <- 20  # Number of choice sets
n_alternatives <- 2  # Number of alternatives per set
# Define the number of choice sets and alternatives per set
n_choice_sets <- 20
n_alternatives <- 2
# Generate an initial design
initial_design <- Modfed(cand.set = candidate_set,
n.sets = n_choice_sets,
n.alts = n_alternatives,
alt.cte = FALSE,
par.draws = par.draws)
update.packages(ask='graphics',checkBuilt=TRUE)
update.packages(ask='graphics',checkBuilt=TRUE)
update.packages(ask='graphics',checkBuilt=TRUE)
q()
install.packages("dplyr")
q()
library(surveydown)
install.packages("crossdes")
library(crossdes)
v <- 100  # Total number of profiles (you can sample these from the full set)
library(crossdes)
v <- 100  # Total number of profiles (you can sample these from the full set)
k <- 8   # Number of profiles in each block
bibd_design <- find.BIB(v = v, k = k)
install.packages("blocksdesign")
bibd_design <- bibo(v = v, b = 35, k = k, r = 7, l = 5, type = 1)
bibd_design <- bibd(v, k)
library(crossdes)
bibd_design <- bibd(v, k)
install.packages("ibd")
library(ibd)
# Define your parameters
v <- 100  # Total number of treatments (profiles)
# Define your parameters
v <- 100  # Total number of treatments (profiles)
k <- 8    # Number of treatments (profiles) per block
# Define your parameters
v <- 100  # Total number of treatments (profiles)
k <- 8    # Number of treatments (profiles) per block
r <- 7    # Number of times each profile appears
b <- (v * r) / k  # Calculate the number of blocks
# Generate the BIBD
bibd_design <- find.BIB(v = v, b = b, k = k, r = r)
print(bibd_design)
bibd(30, 20, 10, 8, 10, 5, pbar = T)
bibd(30, 20, pbar = T)
bibd(30, 20, 20, pbar = T)
bibd(30, 20, 10, 8, 10, 5, pbar = T)
library(cbcTools)
?cbc_design
profiles <- cbc_profiles(
price     = c(1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5),
type      = c("Fuji", "Gala", "Honeycrisp"),
freshness = c('Poor', 'Average', 'Excellent')
)
# Load libraries
library(cbcTools)
library(tidyverse)
# Define profiles with attributes and levels
#profiles <- cbc_profiles(
#    type      = c('Fuji', 'Gala', 'Honeycrisp', 'Pink Lady', 'Red Delicious'),
#    price     = seq(1, 4, 0.5), # $ per pound
#    freshness = c('Excellent', 'Average', 'Poor')
#)
profiles <- cbc_profiles(
tired      = c('never', 'almost never', 'sometimes', 'often', 'always'),
walking      = c('never', 'almost never', 'sometimes', 'often', 'always'),
sports      = c('never', 'almost never', 'sometimes', 'often', 'always'),
concentration      = c('never', 'almost never', 'sometimes', 'often', 'always'),
embarrassed      = c('never', 'almost never', 'sometimes', 'often', 'always'),
unhappiness      = c('never', 'almost never', 'sometimes', 'often', 'always'),
treated      = c('never', 'almost never', 'sometimes', 'often', 'always')
)
design <- cbc_design(
profiles = profiles,
n_resp   = 500, # Number of respondents
n_alts   = 2,    # Number of alternatives per question
n_q      = 8     # Number of questions per respondent
)
# Make a basic survey using the full factorial of all profiles
design <- cbc_design(
profiles = profiles,
n_resp   = 1000, # Number of respondents
n_alts   = 2,    # Number of alternatives per question
n_q      = 8     # Number of questions per respondent
)
profiles <- cbc_profiles(
tired      = c('never', 'almost never', 'sometimes', 'often', 'always'),
walking      = c('never', 'almost never', 'sometimes', 'often', 'always'),
sports      = c('never', 'almost never', 'sometimes', 'often', 'always'),
concentration      = c('never', 'almost never', 'sometimes', 'often', 'always'),
embarrassed      = c('never', 'almost never', 'sometimes', 'often', 'always'),
unhappiness      = c('never', 'almost never', 'sometimes', 'often', 'always'),
treated      = c('never', 'almost never', 'sometimes', 'often', 'always')
)
# Make a basic survey using the full factorial of all profiles
design <- cbc_design(
profiles = profiles,
n_resp   = 1000, # Number of respondents
n_alts   = 2,    # Number of alternatives per question
n_q      = 8     # Number of questions per respondent
)
choices <- cbc_choices(design, obsID = "obsID", priors = NULL)
library(cbcTools)
profiles <- cbc_profiles(
tired      = c('never', 'almost never', 'sometimes', 'often', 'always'),
walking      = c('never', 'almost never', 'sometimes', 'often', 'always'),
sports      = c('never', 'almost never', 'sometimes', 'often', 'always'),
concentration      = c('never', 'almost never', 'sometimes', 'often', 'always'),
embarrassed      = c('never', 'almost never', 'sometimes', 'often', 'always'),
unhappiness      = c('never', 'almost never', 'sometimes', 'often', 'always'),
treated      = c('never', 'almost never', 'sometimes', 'often', 'always')
)
# Make a basic survey using the full factorial of all profiles
design <- cbc_design(
profiles = profiles,
n_resp   = 1000, # Number of respondents
n_alts   = 2,    # Number of alternatives per question
n_q      = 8     # Number of questions per respondent
)
View(profiles)
View(design)
# Make a basic survey using the full factorial of all profiles
design <- cbc_design(
profiles = profiles,
n_resp   = 100, # Number of respondents
n_alts   = 2,    # Number of alternatives per question
n_q      = 8     # Number of questions per respondent
)
for (i in 1:100){
data <- filter(design, obsID == i)
}
View(data)
rowSums(design$tired)
for (i in 1:100){
data <- filter(design, obsID == i)
rowSums(design$tired)
}
for (i in 1:100){
data <- filter(design, obsID == i)
rowSums(data$tired)
}
for (i in 1:100){
data <- filter(design, obsID == i)
rowSums(as.numeric(data$tired))
}
as.vector(data$tired)
sum(as.numeric(data$tired))
mean(data$tired)
mean(as.numeric(data$tired)
mean(as.numeric(data$tired))
mean(as.numeric(data$tired))
data$tired[1]
for (i in 1:100){
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) = data$tired[1]) {
design$s_tired[i] <- T
}
}
for (i in 1:100){
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) = data$tired[1]) {
design$s_tired[i] <- T
}
}
for (i in 1:100){
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) == data$tired[1]) {
design$s_tired[i] <- T
}
}
View(design)
for (i in 1:100) {
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) == as.numeric(data$tired[1])) {
design$s_tired[i] <- TRUE
}
}
View(design)
for (i in 1:100) {
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) == as.numeric(data$tired[1])) {
design$s_tired[i] <- TRUE
} else {
design$s_tired[i] <- F
}
}
View(design)
for (i in 1:100) {
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) == as.numeric(data$tired[1])) {
data$s_tired <- TRUE
} else {
data$s_tired <- F
}
left_join(design, data, by = "profileID")
}
View(design)
library(dplyr)
# Ensure s_tired column exists in the design dataframe
design$s_tired <- FALSE
for (i in 1:100) {
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) == as.numeric(data$tired[1])) {
design$s_tired[design$obsID == i] <- TRUE
}
}
View(design)
for (i in 1:100) {
data <- filter(design, obsID == i)
if (mean(as.numeric(data$tired)) == as.numeric(data$tired[1])) {
design$s_tired[design$obsID == i] <- TRUE
}  if (mean(as.numeric(data$walking)) == as.numeric(data$walking[1])) {
design$s_walking[design$obsID == i] <- TRUE
}  if (mean(as.numeric(data$sports)) == as.numeric(data$sports[1])) {
design$s_sports[design$obsID == i] <- TRUE
}  if (mean(as.numeric(data$concentration)) == as.numeric(data$concentration[1])) {
design$s_concentration[design$obsID == i] <- TRUE
}  if (mean(as.numeric(data$embarrassed)) == as.numeric(data$embarrassed[1])) {
design$s_embarrassed[design$obsID == i] <- TRUE
}  if (mean(as.numeric(data$unhappiness)) == as.numeric(data$unhappiness[1])) {
design$s_unhappiness[design$obsID == i] <- TRUE
}  if (mean(as.numeric(data$treated)) == as.numeric(data$treated[1])) {
design$s_treated[design$obsID == i] <- TRUE
}
}
library(dplyr)
# Ensure the new columns exist and initialize to FALSE
new_columns <- c("tired", "walking", "sports", "concentration", "embarrassed", "unhappiness", "treated")
for (col in new_columns) {
design[[paste0("s_", col)]] <- FALSE
}
for (i in 1:100) {
data <- filter(design, obsID == i)
for (col in new_columns) {
if (mean(as.numeric(data[[col]])) == as.numeric(data[[col]][1])) {
design[[paste0("s_", col)]][design$obsID == i] <- TRUE
}
}
}
View(design)
design <- mutate(design, total = s_tired + s_walking + s_sports + s_concentration + s_embarrassed + s_unhappiness + s_treated))
design <- mutate(design, total = s_tired + s_walking + s_sports + s_concentration + s_embarrassed + s_unhappiness + s_treated)
filter(total == 0)
filter(design, total == 0)
nrow(filter(design, total == 0))
nrow(filter(design, total == 0))/2
knitr::opts_chunk$set(echo = TRUE)
```{r cars, echo=FALSE}
```{r cars}
summary(cars)
install.packages("bookdown")
install.packages("tinytex")
data <- readr::read_csv("\Downloads\block1 rows.csv")
data <- readr::read_csv("/Downloads/block1 rows.csv")
data <- readr::read_csv("/Downloads/block1_rows.csv")
data <- readr::read_csv("~/Downloads/block1_rows.csv")
data <- readr::read_csv("H:/Downloads/block1_rows.csv")
View(data)
bw_data <- select(data, cbc_q1, cbc_q2, cbc_q3, cbc_q4, cbc_q5, cbc_q6, cbc_q7, cbc_q8, cbc_q9, cbc_q10)
library(dplyr)
bw_data <- select(data, cbc_q1, cbc_q2, cbc_q3, cbc_q4, cbc_q5, cbc_q6, cbc_q7, cbc_q8, cbc_q9, cbc_q10)
bw_data
data <- data %>%
rowwise() %>%
mutate(cbc_practice_w = coalesce(cbc_practice_w_tired, cbc_practice_w_walking, cbc_practice_w_sports, cbc_practice_w_concentration, cbc_practice_w_embarrassed, cbc_practice_w_unhappiness, cbc_practice_w_treated)) %>%
mutate(cbc_q1_w = coalesce(cbc_q1_w_tired, cbc_q1_w_walking, cbc_q1_w_sports, cbc_q1_w_concentration, cbc_q1_w_embarrassed, cbc_q1_w_unhappiness, cbc_q1_w_treated)) %>%
mutate(cbc_q2_w = coalesce(cbc_q2_w_tired, cbc_q2_w_walking, cbc_q2_w_sports, cbc_q2_w_concentration, cbc_q2_w_embarrassed, cbc_q2_w_unhappiness, cbc_q2_w_treated)) %>%
mutate(cbc_q3_w = coalesce(cbc_q3_w_tired, cbc_q3_w_walking, cbc_q3_w_sports, cbc_q3_w_concentration, cbc_q3_w_embarrassed, cbc_q3_w_unhappiness, cbc_q3_w_treated)) %>%
mutate(cbc_q4_w = coalesce(cbc_q4_w_tired, cbc_q4_w_walking, cbc_q4_w_sports, cbc_q4_w_concentration, cbc_q4_w_embarrassed, cbc_q4_w_unhappiness, cbc_q4_w_treated)) %>%
mutate(cbc_q5_w = coalesce(cbc_q5_w_tired, cbc_q5_w_walking, cbc_q5_w_sports, cbc_q5_w_concentration, cbc_q5_w_embarrassed, cbc_q5_w_unhappiness, cbc_q5_w_treated)) %>%
mutate(cbc_q6_w = coalesce(cbc_q6_w_tired, cbc_q6_w_walking, cbc_q6_w_sports, cbc_q6_w_concentration, cbc_q6_w_embarrassed, cbc_q6_w_unhappiness, cbc_q6_w_treated)) %>%
mutate(cbc_q7_w = coalesce(cbc_q7_w_tired, cbc_q7_w_walking, cbc_q7_w_sports, cbc_q7_w_concentration, cbc_q7_w_embarrassed, cbc_q7_w_unhappiness, cbc_q7_w_treated)) %>%
mutate(cbc_q8_w = coalesce(cbc_q8_w_tired, cbc_q8_w_walking, cbc_q8_w_sports, cbc_q8_w_concentration, cbc_q8_w_embarrassed, cbc_q8_w_unhappiness, cbc_q8_w_treated)) %>%
mutate(cbc_q9_w = coalesce(cbc_q9_w_tired, cbc_q9_w_walking, cbc_q9_w_sports, cbc_q9_w_concentration, cbc_q9_w_embarrassed, cbc_q9_w_unhappiness, cbc_q9_w_treated)) %>%
mutate(cbc_q10_w = coalesce(cbc_q10_w_tired, cbc_q10_w_walking, cbc_q10_w_sports, cbc_q10_w_concentration, cbc_q10_w_embarrassed, cbc_q10_w_unhappiness, cbc_q10_w_treated)) %>%
ungroup()
View(data)
print(data$cbc_q1_w)
View(data)
print(data$cbc_q2_w)
print(data$cbc_q3_w)
print(data$cbc_q4_w)
print(data$cbc_q5_w)
w_data <- select(data, cbc_q1_w, cbc_q2_w, cbc_q3_w, cbc_q4_w, cbc_q5_w, cbc_q6_w, cbc_q7_w, cbc_q8_w, cbc_q9_w, cbc_q10_w)
w_data
## Presentations
Presentation given at the NIHR Applied Research Collaboration Economics Showcase event held in Manchester on 7th October 2024.
shiny::runApp('OneDrive - Newcastle University/PhD/Code projects/demo-choice-based-conjoint')
runApp('OneDrive - Newcastle University/PhD/Code projects/demo-choice-based-conjoint')
runApp('OneDrive - Newcastle University/PhD/Code projects/demo-choice-based-conjoint')
runApp('OneDrive - Newcastle University/PhD/Code projects/demo-choice-based-conjoint')
rsconnect::writeManifest()
# Define soft/hard launch
library(dplyr)
library(knitr)
library(kableExtra)
launch = "soft"
# Bring in data
if (launch == "soft") {
data <- read.csv("./Data/SOFT_LAUNCH.csv") # Replace this with the final data download from OPUF
}
if (launch == "main") {
data <- read.csv("./Data/MAIN_LAUNCH.csv") # Replace this with the final data download from OPUF
}
data <- data %>%
distinct(dynata_psid, .keep_all = TRUE)
data <- filter(data, !is.na(weight))
data <- filter(data, !is.na(weight))
data <- filter(data, !is.na(eq_vas))
# Define soft/hard launch
library(dplyr)
library(knitr)
library(kableExtra)
launch = "soft"
# Bring in data
if (launch == "soft") {
data <- read.csv("./Data/SOFT_LAUNCH.csv") # Replace this with the final data download from OPUF
}
if (launch == "main") {
data <- read.csv("./Data/MAIN_LAUNCH.csv") # Replace this with the final data download from OPUF
}
data <- data %>%
distinct(dynata_psid, .keep_all = TRUE)
data <- filter(data, !is.na(eq_worried))
data$eq_vas
View(data)
data$respID
count(data$respID)
table(data$respID)
nrow(data$respID)
nrow(data)
unique(data$respID)
sum(unique(data$respID))
duplicated(data$respID)
filter(data, !is.na(eqworried))
filter(data, eqworried!= "")
x <- filter(data, eqworried!= "")
# Define soft/hard launch
library(dplyr)
library(knitr)
library(kableExtra)
launch = "soft"
# Bring in data
if (launch == "soft") {
data <- read.csv("./Data/SOFT_LAUNCH.csv") # Replace this with the final data download from OPUF
}
if (launch == "main") {
data <- read.csv("./Data/MAIN_LAUNCH.csv") # Replace this with the final data download from OPUF
}
data <- data %>%
distinct(dynata_psid, .keep_all = TRUE)
data <- filter(data, !is.na(eq_vas))
# Bring in data
if (launch == "soft") {
data <- read.csv("./Data/SOFT_LAUNCH.csv") # Replace this with the final data download from OPUF
}
if (launch == "main") {
data <- read.csv("./Data/MAIN_LAUNCH.csv") # Replace this with the final data download from OPUF
}
duplicated(data$respID)
data %>%
distinct(respID, .keep_all = FALSE)
data %>%
distinct(respID, .keep_all = TRUE)
data %>%
distinct(respID, .keep_all = FALSE)
data %>%
!distinct(respID, .keep_all = FALSE)
data %>%
filter(duplicated(respID) | duplicated(respID, fromLast = TRUE))
data %>%
filter(duplicated(respID) | duplicated(respID, fromLast = TRUE)) %>%
select(respID)
View(data)
nrow(unique(data$respID))
table(unique(data$respID))
length(unique(data$respID))
here()
library(here)
setwd("~/Dropbox/opuf-adult/reports/markdown/hesg")
library(here)
here()
