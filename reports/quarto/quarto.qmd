---
title: "Development of a value-based scoring system for the WAItE using the OPUF in a sample of adults"
author:
  - name: William King*
    email: w.king2@newcastle.ac.uk
    affiliations:
      - id: ncl
        name: Newcastle University
        department: Health Economics Group
        address: University, Barras Bridge
        city: Newcastle upon Tyne
        state: Tyne and Wear
        postal-code: NE1 7RU
  - name: Tomos Robinson
    affiliations:
      - id: ncl
        name: Newcastle University
        department: Health Economics Group
        address: University, Barras Bridge
        city: Newcastle upon Tyne
        state: Tyne and Wear
        postal-code: NE1 7RU
  - name: Angela Bate
    affiliations:
      - id: north
        name: Northumbria University
        department: Nursing, Midwifery and Health
        address: Ellison Pl
        city: Newcastle upon Tyne
        state: Tyne and Wear
        postal-code: NE1 8ST
  - name: Laura Ternent
    affiliations:
      - id: ncl
        name: Newcastle University
        department: Health Economics Group
        address: University, Barras Bridge
        city: Newcastle upon Tyne
        state: Tyne and Wear
        postal-code: NE1 7RU

abstract: |
  
  **Background:** Online personal utility functions (OPUF) present a new method for eliciting preferences. In this study we used the OPUF to elicit a health state utility value set for the Weight-specific Adolescent Instrument for Economic-evaluation (WAItE) with a representative sample of the UK adult population.

  **Methods:** WAItE OPUF survey design was informed by prior qualitative work. The survey consisted of the WAItE descriptive system, attribute weighting, level rating (per attribute) and a VAS anchoring task. Personal utility functions were estimated on the individual level for all participants. Personal utility functions were aggregated and combined with the anchoring factor to give the social utility function and utility value set. Preference heterogeneity was assessed using Euclidean distance and PERMANOVA to explore preference variation within the sample. An experimental sensitivity analysis dichotomised preference heterogeneity into anchoring variation and attribute weighting/level rating variation.

  **Results:** A total of 300 participants completed the WAItE OPUF survey. The sample was broadly representative of the UK adult population. Participants, on average, took less than 10 minutes to complete the survey. The most important attributes were tiredness and unhappiness, while least important attributes were sports and embarrassment. Social utility values and the anchoring utility value estimated were comparable to previous studies. Preferences generally were heterogeneous, especially among different ages. Younger participants assigned lower utility values to WAItE health states and provided significantly lower scores on the VAS anchoring task compared to older participants.

  **Conclusion:** This study successfully elicited health state utility values for the WAItE using the OPUF. Preference heterogeneity analysis identified differences in preferences for different age groups and a further valuation study is ongoing to explore whether this heterogeneity exists between adults and adolescents.
keywords: 
  - Health state valuation
  - preference elicitation
  - quality of life
date: last-modified
bibliography: bibliography.bib
csl: vancouver.csl
format:
  html:
    toc: true
    toc-location: right
# Enable the below sections if you want pdf or docx
# format:
#   docx:
#     toc: false
#     number-sections: true
#     highlight-style: github
# format:
#   elsevier-pdf:
#     keep-tex: true
#     journal:
#       name: Health Economics Study Group
#       formatting: preprint
#       # model: 3p # Don't set a model with preprint
#       cite-style: number
#     header-includes:
#       - \usepackage[a4paper,margin=1in,textwidth=6.5in]{geometry}
---

*Disclaimer:* This is a work-in-progress, please do not redistribute or cite without the authors permission. This work was supported by the NIHR-ARC and Newcastle University. 

*Acknowledgements:* We would like to thank Paul Schneider and Valorem Health for collaborating on this project.

*Code availability:* An interactive document (HTML) which includes the live survey is available [here](https://willking98.github.io/opuf-adult/). Source code for the analysis and this Quarto generated PDF are available [here](https://github.com/willking98/opuf-adult).

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
setwd("~/Dropbox/opuf-adult") # convert this to here for reproducibility
source("X_Run.R")
```

# Introduction {#sec-introduction}
```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# include in thesis but not paper?
# This chapter presents the introduction, methods, results and discussion from an empirical study developing a utility value set for the WAItE using online personal utility functions (OPUF) with a representative sample of UK adults.  
```

## Compositional preference elicitation methods

Preference elicitation methods typically, fall into two categories: compositional and decompositional [@Keeney1979DecisionsTrade-Offs; @Marsh2016MultipleForce; @Belton2002MultipleAnalysis]. That is, methods such as DCE, BWS and TTO elicit preference orderings from individuals for an entire health state (composed of a combination of attributes and levels) and then responses are decomposed to identify marginal contributions of each attribute and level in each health state. Models like multinomial logit, mixed logit and latent class are frequently used to decompose responses to decompositional preference elicitation tasks [@Hauber2016StatisticalForce]. Coefficients estimated in these models form the basis of dis/utility values for each attribute and level in a descriptive system. 

Conversely, compositional methods seek to identify preferences for each attribute weighting and level rating individually for the number of attributes and levels in a given descriptive system. Therefore, statistical models to elicit coefficients for each individual attribute and level are not required and responses to each attribute weighting and level rating are combined (in addition to an anchoring factor) to yield dis/utility values for each attribute and level in the descriptive system. Compositional approaches can take many forms from simple VAS scores to using semantic categories and ranking methods [@BanaECosta1999TheApplication; @Danner2011IntegratingPreferences; @Oliveira2018ValuingStates]. These approaches have previously been used successfully in multi-criteria decision analysis (MCDA), but have been used less extensively in the preference elicitation space. Since the development of the OPUF, compositional approaches to elicit preferences have become more commonplace and a number of countries are using the OPUF to elicit value sets specific to their population [@Brodszky2023PCR108States]. 

## From PUF to OPUF
Personal utility functions (PUF) were first used in the context of preference elicitation by Devlin et al. (2019) [@Devlin2019AFunctions] to estimate the feasibility for using this approach to estimate a value set for the EQ-5D-5L. Since the feasibility for the underlying PUF methods were established, the approach has been expanded by Schneider and colleagues [@Schneider2022TheStates] and converted into an online personal utility functions (OPUF) survey built initially using RShiny and subsequently using Javascript (available [here](https://eq5d5l.me)). Since the development of the OPUF, a number of descriptive systems and different research teams have begun using this method to elicit value sets [@Bray2024DevelopmentImpairment; @Brodszky2023PCR108States].  

## An overview of the OPUF structure
### Attribute weighting 
This section is composed of two parts. First, attribute ranking is completed where participants identify their most important attribute (@fig-importantattribute). Second, respondents complete the attribute weighting (swing weighting) where the relative importance of other attributes is ascertained using their most important attribute as a reference point (@fig-swing). These questions are presented in @fig-attribute. 

::: {#fig-attribute layout-ncol=2}

![Most important attribute](/outputs/figures/relative_importance.png){#fig-importantattribute}

![Swing rating](../../outputs/figures/swing_rating.png){#fig-swing}

Attribute weighting
:::

### Level ratings 
This element of the OPUF has varied across different iterations of the survey. Schnieder et al. (2022) [@Schneider2022TheStates] asked participants to rank the levels within the descriptive system generally (i.e. for any given attribute), while other iterations have administered separate level rating questions for each attribute in the descriptive system [@Bray2024DevelopmentImpairment]. Selection of method requires a trade-off between participant burden and sensitivity of level ratings to each attribute. @fig-level presents the level rating question for the tiredness and treated differently attributes of the WAItE. 

::: {#fig-level layout-ncol=2}

![Level rating: Tiredness](../../outputs/figures/level_rating.png){#fig-levelrating}

![Level rating: Treated differently](../../outputs/figures/level_rating2.png){#fig-levelrating2}

Level rating
:::

\newpage

### Anchoring factor 
A task is required to rescale the latent coefficients estimated via combining level ratings and attribute weights onto the QALY scale. Participants are presented with a binary choice between the PITS state (or another state) of a given descriptive system and "being dead" (@fig-anchor1). If the PITS state is chosen, participants are asked to rank the PITS state on a VAS from 1 (full health) to 0 (dead). If "being dead" is chosen, participants are asked to rank "being dead" on a VAS from 1 (full health) to 0 (PITS state) (@fig-anchor2). Responses to these respective questions provide the anchoring factor. Anchoring questions, such that PITS is preferred to dead, are presented in @fig-anchoring.

::: {#fig-anchoring layout-ncol=2}

![PITS-dead](../../outputs/figures/anchor1.png){#fig-anchor1}

![PITS-VAS](../../outputs/figures/anchor2.png){#fig-anchor2}

Anchoring factor
:::

## OPUF logic and mathematics {#sec-OPUF_methods}
This section presents the logic and underlying mathematics required to convert the raw OPUF responses from one person into an anchored value set for the WAItE descriptive system. This example assumes that level ratings are obtained for each attribute separately, therefore the mathematics presented here differs to those presented elsewhere [@Schneider2022TheStates]. Example response data are used for demonstration in this section and are presented in @tbl-exampledata. 

\newpage

### Example responses
```{r, echo=FALSE}
example_opuf_data <- data.frame(
  Response = c("Level rating: Never", "Level rating: Almost Never", "Level rating: Sometimes", "Level rating: Often", "Level rating: Always", 
               "Attribute Weighting"),
  Tired = c(0, 14, 57, 83, 100, 28),
  Walking = c(0, 26, 55, 82, 100, 33),
  Sports = c(0, 21, 63, 85, 100, 36),
  Concentration = c(0, 15, 54, 86, 100, 45),
  Embarrassed = c(0, 16, 38, 64, 100, 100),
  Unhappiness = c(0, 12, 26, 38, 100, 34),
  Treated = c(0, 19, 66, 91, 100, 56)
)

```

```{r, echo=FALSE}
#| label: tbl-exampledata
#| tbl-cap: Example individual responses to the OPUF
kable(example_opuf_data) 

# footnote(
#     general = c("WAItE PITS better than dead = Yes",
#     "Anchoring Task Response = 20", 
#                "PITS Utility Value = 0.2"),
#     footnote_as_chunk = TRUE,
#     escape = FALSE
#   )
```

Level ratings (presented in @tbl-exampledata)  are converted to coefficients bounded between 0-1 (shown in @eq-level-rescale). Level rating coefficients are presented in @eq-level-matrix. Attribute weights (presented in @tbl-exampledata) are then normalised to sum to the value of 1 by dividing each weight by the sum of all weights (shown in @eq-weight-normalise). Normalised attribute weights are presented in @eq-weight-vector. 

$$
    L_{ij} \cdot 0.01
$$ {#eq-level-rescale}

$$
L_{ij} = 
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.14 & 0.26 & 0.21 & 0.15 & 0.16 & 0.12 & 0.19 \\
0.57 & 0.55 & 0.63 & 0.54 & 0.38 & 0.26 & 0.66 \\
0.83 & 0.82 & 0.85 & 0.86 & 0.64 & 0.38 & 0.91 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 \\
\end{bmatrix}
$$ {#eq-level-matrix}

$$
    \frac{w_{j}}{\sum{w_j}}
$$ {#eq-weight-normalise}

$$
w_j = \begin{bmatrix}
    0.08& 0.10& 0.11& 0.14& 0.30& 0.10& 0.17
\end{bmatrix} 
$$ {#eq-weight-vector}


Combining the attribute weights (@eq-weight-vector) with the level coefficients (@eq-level-matrix) via element-wise multiplication (shown in @eq-element-wise-multiplication gives the coefficient matrix presented in @eq-coeff-matrix. Once the coefficient matrix has been estimated, preference values can be estimated on the 0-1 QALY scale where the worst health state (PITS state denoted 5555555) is zero and the best health state (denoted 1111111) is one. These latent coefficients must now be rescaled to incorporate the results from the PITS anchoring task so that the minimum utility value possible is equal to the PITS value. 

$$
    L_{ij} \cdot  w_{j} = {M}_{ij}
$$ {#eq-element-wise-multiplication}

$$
M_{ij} =  
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.01 & 0.03 & 0.02 & 0.02 & 0.05 & 0.01 & 0.03 \\
0.05 & 0.05 & 0.07 & 0.07 & 0.11 & 0.03 & 0.11 \\
0.07 & 0.08 & 0.09 & 0.12 & 0.19 & 0.04 & 0.15 \\
0.08 & 0.10 & 0.11 & 0.14 & 0.30 & 0.10 & 0.17
\end{bmatrix}
$$ {#eq-coeff-matrix}

To rescale the latent coefficient matrix to incorporate the anchoring task, the coefficient matrix is multiplied by the compliment of the PITS value (shown in @eq-anchoring) to give the anchored coefficient matrix presented in @eq-anchored-matrix. 

$$
    M_{ij} \cdot (1-P) \quad \backepsilon \quad P = 0.2 
$$ {#eq-anchoring}

$$
V_{ij} =  
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.01 & 0.02 & 0.02 & 0.02 & 0.04 & 0.01 & 0.02 \\
0.04 & 0.04 & 0.06 & 0.06 & 0.09 & 0.02 & 0.09 \\
0.06 & 0.06 & 0.07 & 0.10 & 0.15 & 0.03 & 0.12 \\
0.06 & 0.08 & 0.09 & 0.11 & 0.24 & 0.08 & 0.14 \\
\end{bmatrix}
$$ {#eq-anchored-matrix}

Once the attribute and level labels are reintroduced to the anchored coefficient matrix this forms the value set which presents the disutility corresponding to each attribute level combination presented in the WAItE. @tbl-example-valueset presents the WAItE example PUF value set. @eq-HS123 provides examples of how to estimate a utility value given a specific WAItE health state. 

```{r, echo = FALSE}
example_valueset <- data.frame(
  "Attribute level" = c("Never", "Almost Never", "Sometimes", "Often", "Always"),
  Tired = c(0, 0.01, 0.04, 0.06, 0.06),
  Walking = c(0, 0.02, 0.04, 0.06, 0.08),
  Sports = c(0, 0.02, 0.06, 0.07, 0.09),
  Concentration = c(0, 0.02, 0.06, 0.10, 0.11),
  Embarrassed = c(0, 0.04, 0.09, 0.15, 0.24),
  Unhappiness = c(0, 0.01, 0.02, 0.03, 0.08),
  Treated = c(0, 0.02, 0.09, 0.12, 0.14)
)
```

```{r, echo = FALSE}
#| label: tbl-example-valueset
#| tbl-cap: WAItE example PUF value set
kable(example_valueset, col.names = c("Attribute level", "Tired", "Walking", "Sports", "Concentration", "Embarrassed", "Unhappiness", "Treated"), digits = 2)
```

$$
\begin{aligned}
\text{Health State [5555555]} & \Rightarrow 1 - (0.06 + 0.08 + 0.09 + 0.11 + 0.24 + 0.08 + 0.14) = 0.20 \\
\text{Health State [5223445]} & \Rightarrow 1 - (0.06 + 0.02 + 0.02 + 0.06 + 0.15 + 0.03 + 0.14) = 0.52 \\
\text{Health State [2222222]} & \Rightarrow 1 - (0.03 + 0.02 + 0.01 + 0.01 + 0.02 + 0.02 + 0.04) = 0.85
\end{aligned}
$$ {#eq-HS123}

## Aggregation to social utility function
The OPUF is designed to be able to estimate personal utility functions and so estimation occurs on an individual basis. Aggregating personal utility functions to a social utility function (SUF) takes place by taking a mean of all the individual personal utility functions from your sample. This operation is presented in @eq-meanvalueset. 

$$
\bar{V}_{{ij}} = \frac{\sum_{V_{{ij}}}^{}}{N}
$$ {#eq-meanvalueset}

# Methods
## Recruitment
This study recruited 300 adults to respond to a quality-of-life survey hosted online. Study participants were recruited based on specific quotas (age, ethnicity and gender) to form a representative sample based on UK census data. The survey was hosted on the [Prolific](https://www.prolific.com) platform which invited paid respondents to complete the WAItE version of the OPUF survey. A demonstration of the OPUF survey and questions is available [here](https://survey.valorem.health/waite_opuf_adult2). Informed consent was obtained at the outset of the survey and participants reserved the right to withdraw at any point without giving a reason. Participants who withdrew were not paid and their data deleted. Participation in this survey was estimated to take approximately fifteen minutes to complete and participants received £2.50 as a payment upon completion. This is in line with reimbursements rates from other OPUF studies [@Schneider2022TheStates; @Bray2024DevelopmentImpairment] and is in line with recommended reimbursement rates from [Prolific](https://www.prolific.com). The survey was designed to be an unassisted survey administered online (no face-to-face contact) and no identifiable data was collected. Statistical analysis was conducted on the survey data. Newcastle University Medical School Ethics Committee approved this study (reference 49737/2023). The survey structure is detailed in [@sec-surveystructure]. 

## Survey structure {#sec-surveystructure}
1. Consent and Prolific ID: Participants were asked to consent to participate and enter their unique Prolific ID. This enables demographic information held by Prolific on their participants to be linked to each respondent. 
2. WAItE descriptive system: Participants were asked to complete the WAItE descriptive system (presented in @fig-waite-descriptive) to describe their current health state. 
3. Attribute selection: Participants were presented with the worst level for each WAItE attribute and asked to choose which health problem would have the most negative impact on their quality of life. The attribute chosen is then used in the subsequent attribute swing weighting task. 
4. Attribute swing weighting: Participants were presented with each attribute in the WAItE and asked to consider an improvement from the worst level of that attribute to the best level of that attribute. Participants were asked to rank this improvement on a visual slider from 0-100 where the most important attribute (chosen in the previous task) is fixed at 100. Participants were reminded to use their most important attribute as a reference point.
5. Level rating: Participants were presented with a specific attribute of the WAItE and shown each level within that attribute. Levels best and worst (never and always) were fixed at 0 and 100 respectively. Participants were asked to rank the intermediate levels within each attribute using the fixed levels as a reference point. 
6. Anchoring: Participants were presented with a binary choice asking whether they prefer the worst state of the WAItE (PITS state) or death. If participants choose the worst state of the WAItE, a second question is asked which asks them to rank the WAITE PITS state on a visual analogue scale where zero is labelled as being dead and one hundred is labelled as no health problems. If participants choose death in the binary choice, they were asked to rank being dead on a visual analogue scale where zero is labelled as the WAItE PITS state and one hundred is labelled as no health problems. 
7. Survey feedback and demographic questions: Participants were asked about how difficult they found the task to complete and demographic information on age, gender, ethnicity, education, employment and weight status.


![WAItE descriptive system](../../outputs/figures/WAItE descriptive.png){#fig-waite-descriptive width=400}

::: {.content-visible when-format="html"}
## Live survey {#sec-livesurvey}
::: {.callout-note collapse="true"}
### Live Survey 
```{=html}
<iframe 
    width="800" 
    height="600" 
    src="https://survey.valorem.health/waite_opuf_adult2" 
    title="Information">
</iframe>
```
:::

:::


## Missing data
Through the survey design process, the potential for large amounts of missing data was mitigated by ensuring responses were compulsory to certain questions. However for ethical reasons, we allowed participants to not answer the questions relating to death. For participants who do not provide responses to the anchoring questions, their responses were imputed using multiple imputation by chained equations (MICE) [@White2011MultiplePractice] which were informed by demographic information and attribute weighting responses. 

## Preference heterogeneity
As PUFs are estimated on an individual basis, exploring preference heterogeneity between individuals in the sample is straightforward. Investigating the heterogeneity of preferences between individuals, requires a measure of dis/similarity to quantify how far apart two PUFs are [@Schneider2024ExploringLevel]. The measurement and estimation of preference heterogeneity in this section will follow methods detailed by Schneider et al. (2024) [@Schneider2024ExploringLevel]. Each PUF estimated in this study was represented by a vector of 78,125 health state utility values for each respondent in the sample. In order to assess the dis/similarity between these PUFs, we used the euclidean difference measure (EUD). Analogous to a line between two points on a two dimensional plane, the EUD between two PUFs denotes the shortest path length in a 78,125 dimensional space. It is computed as the square root of the sum of the squared differences between the PUFs of individuals $i$ and $j$ (presented in @eq-EUD). Once PUFs have been estimated for all individuals in the sample, pairwise EUD was estimated for all possible pairwise combinations within the sample. Pairwise EUD was stored in an [N $\times$ N] distance matrix.   

$$ 
  \begin{aligned}
    d_{EUD}(i,j) & =\sqrt{\sum_{}^{}(u_{i}(s_{1})-u_{j}(s_{1}))^{2}+ ... +(u_{i}(s_{78125})-u_{j}(s_{78125}))^{2}}\\
      & \backepsilon \quad \quad s = \{1111111, 2111111, ..., 5555555\}\\
  \end{aligned}
$$ {#eq-EUD}

## Permutational analysis of variance
Permutational analysis of variance (PERMANOVA), analogous to analysis of variance, is a geometric partitioning of variation across a multivariate data cloud, defined in the space of any given dissimilarity measure, in response to one or more groups [@Anderson2017; @Anderson2013PERMANOVATesting]. This method of statistical testing has been used most commonly in ecological research to test for population dispersion among different subgroups [@Souza2013PopulationEstuary]. PERMANOVA decomposes the total distances between observations (SS$_T$) into within-groups (SS$_W$) and between groups sum-of-squares (SS$_B$). @eq-sumsquares details the estimation of total and within-groups sum-of-squares. Mathematical notation presented here is reproduced from Schneider et al. (2024) [@Schneider2024ExploringLevel] for consistency.   

$$ 
    SS_{T} = \frac{1}{N}\sum_{i=1}^{N-1}\sum_{j=i+1}^{N}d(i,j)^{2}; \quad SS_{W} = \sum_{i=1}^{N-1}\sum_{j=i+1}^{N}d(i,j)^{2}\epsilon_{ij}^{\ell}/n_{\ell}
$$ {#eq-sumsquares}

where N is the total sample size (=300), $d(i,j)^2$ is the squared distance between the PUFs of participants $i$ and $j$, $\epsilon_{i,j}$ indicator which is 1, if participants $i$ and $j$ belong to the same group, and 0 if they do not, and $n_{\ell}$ is the size for group $\ell$. Then, SS$_B$ can then be calculated as SS$_B$ = SS$_T$ – SS$_W$, which allows calculating the pseudo F statistic for $p$ groups:

$$
F= \frac{(\frac{SS_B}{p-1})}{(\frac{SS_W}{N-p})}
$$ {#eq-ssb}

Further details about the mathematical and statistical properties of PERMANOVA are available elsewhere [@Schneider2024ExploringLevel; @Anderson2017; @Anderson2013PERMANOVATesting]. In this study, we used PERMANOVA to explore the variability in WAItE health state preferences (individual value sets) between various subgroups. A multivariate PERMANOVA model was estimated with subgroups of: age, gender, self-reported weight status, education, employment status and ethnicity.  

## Sensitivity analysis
In an experimental sensitivity analysis, preference heterogeneity was assessed using EUD estimated based on individual's personal utility functions anchored using the social PITS utility value (henceforth referred to as EUD2). This differed to prior preference heterogeneity estimation as individual variation in PITS utility values were not included in the EUD2 estimation. EUD2 was entirely composed by differences in level ratings and attribute weights. Further details on the derivation of EUD2 are presented in the online [Appendix](https://willking98.github.io/opuf-adult/).

An additional analysis of preference heterogeneity in anchoring values was conducted using a generalised linear model. A multivariate Gamma GLM (with log-link function) was constructed to explore the relationship between PITS utility values and demographic information. This facilitated exploration into how anchoring preferences differed among different demographic subgroups in our sample. 

# Results
## Study participants
A sample of 334 individuals were approached to participate in the study via the survey company [Prolific](https://www.prolific.com). Individuals that successfully inputted their unique Prolific ID and obtained a correct completion code from the end of the study were included in the analysis sample and received a small payment (£2.50) for their participation. Seven participants were excluded from the study as they had an incorrect completion code and did not enter the correct unique Prolific ID. Therefore, no data was available on those seven participants and they were excluded from the analysis. An additional participant was excluded from the analysis due to completing the survey in eighteen seconds (well under the pre-specified minimum time limit of 2 minutes). Two respondents timed-out while completing the survey and were therefore not included. Twenty-four individuals chose not complete the study (referred to by Prolific as 'returned' participants). This left an analysis sample of N=300 participants who successfully completed the survey. The sample was representative of the UK based on age, gender and ethnicity. A summary of demographic information collected in the OPUF are presented in @tbl-demographic.  

## Survey duration
The mean (SD) and median (IQR) survey completion time in minutes was 9.66 (5.85) and 8.15 (5.88; 11.89). @tbl-time summarises how much time was spent completing each individual section of the survey.

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# Time
# Convert start time from milliseconds to POSIXct
data$start_time <- as.POSIXct(data$timeTracker_surveyStartTime / 1000, origin = "1970-01-01", tz = "Europe/London")

data$start_time_minutes <- as.POSIXct(((data$timeTracker_surveyStartTime)/1000), origin="1970-01-01", tz="Europe/London")
data$time_taken_minutes <- as.numeric(as.POSIXct(((data$timeTracker_surveyEndTime)/1000), origin="1970-01-01", tz="Europe/London") - as.POSIXct(((data$timeTracker_surveyStartTime)/1000), origin="1970-01-01", tz="Europe/London"))

# Calculate time taken in seconds
data$time_taken <- as.numeric(
  as.POSIXct(data$timeTracker_surveyEndTime / 1000, origin = "1970-01-01", tz = "Europe/London") -
  as.POSIXct(data$timeTracker_surveyStartTime / 1000, origin = "1970-01-01", tz = "Europe/London"),
  units = "secs"
)

# time_tab <- matrix(NA, nrow = 9, ncol = 5)
#
# time_tab[1,] <- c(
#   "WAItE",
#   paste(format(round(mean(data$timeTracker_EPRO1_seconds), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_EPRO1_seconds), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$timeTracker_EPRO1_seconds), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_EPRO1_seconds, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_EPRO1_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_EPRO1_seconds), 1), nsmall = 1),
#   format(round(max(data$timeTracker_EPRO1_seconds), 1), nsmall = 1)
# )
#
# time_tab[2,] <- c(
#   "Attribute ranking",
#   paste(format(round(mean(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_OPUFRanking1_seconds, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_OPUFRanking1_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1),
#   format(round(max(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1)
# )
#
# time_tab[3,] <- c(
#   "Attribute weighting",
#   paste(format(round(mean(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_OPUFSwingWeight1_seconds, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_OPUFSwingWeight1_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1),
#   format(round(max(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1)
# )
#
# time_tab[4,] <- c(
#   "Level rating",
#   paste(format(round(mean(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_OPUFLevelRating_seconds, 0.25, na.rm=T), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_OPUFLevelRating_seconds, 0.75, na.rm=T), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), nsmall = 1),
#   format(round(max(data$timeTracker_OPUFLevelRating_seconds, na.rm=T), 1), nsmall = 1)
# )
#
# time_tab[5,] <- c(
#   "PITS vs death",
#   paste(format(round(mean(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_OPUFDeadChoice_seconds, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_OPUFDeadChoice_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1),
#   format(round(max(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1)
# )
#
# time_tab[6,] <- c(
#   "PITS-VAS",
#   paste(format(round(mean(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), ")", sep = ""),
#   format(paste(format(round(median(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1),
#   format(round(max(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1)
# ))
#
# time_tab[7,] <- c(
#   "PITS-VAS",
#   paste(format(round(mean(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), " (", format(round(sd(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), " (", format(round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1),
#   format(round(max(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1)
# )
#
# time_tab[8,] <- c(
#   "Total (secs)",
#   paste(format(round(mean(data$time_taken), 1), nsmall = 1), " (", format(round(sd(data$time_taken), 1), nsmall = 1), ")", sep = ""),
#   paste(format(round(median(data$time_taken), 1), nsmall = 1), " (", format(round(quantile(data$time_taken, 0.25), 1), nsmall = 1), "; ", format(round(quantile(data$time_taken, 0.75), 1), nsmall = 1), ")", sep = ""),
#   format(round(min(data$time_taken), 1), nsmall = 1)
#   format(round(max(data$time_taken), 1), nsmall = 1)
# )
#
# time_tab[9,] <- c(
#   "Total (mins)",
#   paste(format(round(mean(data$time_taken_minutes), 2), nsmall = 2), " (", format(round(sd(data$time_taken_minutes), 2), nsmall = 2), ")", sep = ""),
#   paste(format(round(median(data$time_taken_minutes), 2), nsmall = 2), " (", format(round(quantile(data$time_taken_minutes, 0.25), 2), nsmall = 2), "; ", format(round(quantile(data$time_taken_minutes, 0.75), 2), nsmall = 2), ")", sep = ""),
#   format(round(min(data$time_taken_minutes), 2), nsmall = 2),
#   format(round(max(data$time_taken_minutes), 2), nsmall = 2)
# )

# Initialize the matrix
time_tab <- matrix(NA, nrow = 8, ncol = 5)

# Row 1: WAItE
time_tab[1, ] <- c(
  "WAItE",
  paste(format(round(mean(data$timeTracker_EPRO1_seconds), 1), nsmall = 1), 
        " (", format(round(sd(data$timeTracker_EPRO1_seconds), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$timeTracker_EPRO1_seconds), 1), nsmall = 1), 
        " (", format(round(quantile(data$timeTracker_EPRO1_seconds, 0.25), 1), nsmall = 1), "; ", 
        format(round(quantile(data$timeTracker_EPRO1_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$timeTracker_EPRO1_seconds), 1), nsmall = 1),
  format(round(max(data$timeTracker_EPRO1_seconds), 1), nsmall = 1)
)

# Row 2: Attribute ranking
time_tab[2, ] <- c(
  "Attribute ranking",
  paste(format(round(mean(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1), 
        " (", format(round(sd(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1), 
        " (", format(round(quantile(data$timeTracker_OPUFRanking1_seconds, 0.25), 1), nsmall = 1), "; ", 
        format(round(quantile(data$timeTracker_OPUFRanking1_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1),
  format(round(max(data$timeTracker_OPUFRanking1_seconds), 1), nsmall = 1)
)

# Row 3: Attribute weighting
time_tab[3, ] <- c(
  "Attribute weighting",
  paste(format(round(mean(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1), 
        " (", format(round(sd(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1), 
        " (", format(round(quantile(data$timeTracker_OPUFSwingWeight1_seconds, 0.25), 1), nsmall = 1), "; ", 
        format(round(quantile(data$timeTracker_OPUFSwingWeight1_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1),
  format(round(max(data$timeTracker_OPUFSwingWeight1_seconds), 1), nsmall = 1)
)

# Row 4: Level rating
time_tab[4, ] <- c(
  "Level rating",
  paste(format(round(mean(data$timeTracker_OPUFLevelRating_seconds, na.rm = TRUE), 1), nsmall = 1), 
        " (", format(round(sd(data$timeTracker_OPUFLevelRating_seconds, na.rm = TRUE), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$timeTracker_OPUFLevelRating_seconds, na.rm = TRUE), 1), nsmall = 1), 
        " (", format(round(quantile(data$timeTracker_OPUFLevelRating_seconds, 0.25, na.rm = TRUE), 1), nsmall = 1), "; ", 
        format(round(quantile(data$timeTracker_OPUFLevelRating_seconds, 0.75, na.rm = TRUE), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$timeTracker_OPUFLevelRating_seconds, na.rm = TRUE), 1), nsmall = 1),
  format(round(max(data$timeTracker_OPUFLevelRating_seconds, na.rm = TRUE), 1), nsmall = 1)
)

# Row 5: PITS vs death
time_tab[5, ] <- c(
  "PITS vs death",
  paste(format(round(mean(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1), 
        " (", format(round(sd(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1), 
        " (", format(round(quantile(data$timeTracker_OPUFDeadChoice_seconds, 0.25), 1), nsmall = 1), "; ", 
        format(round(quantile(data$timeTracker_OPUFDeadChoice_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1),
  format(round(max(data$timeTracker_OPUFDeadChoice_seconds), 1), nsmall = 1)
)

# Row 6: PITS-VAS
time_tab[6, ] <- c(
  "PITS-VAS",
  paste(format(round(mean(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), 
        " (", format(round(sd(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1), 
        " (", format(round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.25), 1), nsmall = 1), "; ", 
        format(round(quantile(data$timeTracker_OPUFVasAnchoring_seconds, 0.75), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1),
  format(round(max(data$timeTracker_OPUFVasAnchoring_seconds), 1), nsmall = 1)
)

# Row 8: Total (secs)
time_tab[7, ] <- c(
  "Total (secs)",
  paste(format(round(mean(data$time_taken), 1), nsmall = 1), 
        " (", format(round(sd(data$time_taken), 1), nsmall = 1), ")", sep = ""),
  paste(format(round(median(data$time_taken), 1), nsmall = 1), 
        " (", format(round(quantile(data$time_taken, 0.25), 1), nsmall = 1), "; ", 
        format(round(quantile(data$time_taken, 0.75), 1), nsmall = 1), ")", sep = ""),
  format(round(min(data$time_taken), 1), nsmall = 1),
  format(round(max(data$time_taken), 1), nsmall = 1)
)

# Row 9: Total (mins)
time_tab[8, ] <- c(
  "Total (mins)",
  paste(format(round(mean(data$time_taken_minutes), 2), nsmall = 2), 
        " (", format(round(sd(data$time_taken_minutes), 2), nsmall = 2), ")", sep = ""),
  paste(format(round(median(data$time_taken_minutes), 2), nsmall = 2), 
        " (", format(round(quantile(data$time_taken_minutes, 0.25), 2), nsmall = 2), "; ", 
        format(round(quantile(data$time_taken_minutes, 0.75), 2), nsmall = 2), ")", sep = ""),
  format(round(min(data$time_taken_minutes), 2), nsmall = 2),
  format(round(max(data$time_taken_minutes), 2), nsmall = 2)
)

colnames(time_tab) <- c("Section", "Mean (SD)", "Median (Q1; Q3)", "Min", "Max")  # adjusted the column name


```
```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-time
#| tbl-cap: Survey completion times (secs)
kable(time_tab, digits = 3, align = c("l", "r", "r", "r", "r"))

```

## WAItE descriptive system
Responses to the WAItE descriptive system are presented in @tbl-demographic. Feeling tired and avoiding doing sport were the attributes that were most frequently experienced by participants in our analysis sample. WAItE summary statistics were in line with results from previous studies [@Robinson2019EstimatingEvaluation].

## Level ratings
Level ratings are presented individually for each different attribute in @tbl-level. The best and worst levels (*Always* and *Never*) were fixed at 0 and 100 respectively. The second best level (*Almost never*) had the lowest VAS score in the Sports and Embarrassment attribute, while the second worst level (*Often*) had the highest VAS score in the Concentration attribute. In this question, higher VAS scores indicate worse states of health.

\newpage

```{r, echo = FALSE}
# Data preparation
demographic_data <- data.frame(
  `Participant Characteristics`= c(
    "Age", "18-24", "25-34", "35-44", "45-54", "55-64", "65-90", "Not Stated",
    "Gender", "Female", "Male", "Non-binary",
    "Ethnicity", "White", "Asian", "Black", "Mixed", "Other",
    "Weight Status", "Normal", "Overweight", "Obese", "Underweight", "Prefer not to say",
    "Education", "Degree", "A Level", "Higher Education", "Other", "GCSE A-C", "GCSE D-G",
    "Occupation", "Full-time", "Part-time", "Not Paid", "Other", "Student", "Unemployed", 
    "Not Stated", "Starting a New Job",
    "WAItE", "Tiredness", "Walking", "Sport", "Concentration", 
    "Embarrassment", "Unhappiness", "Treated differently", "Total"
  ),
   `N (%)`= c(
    "", "32 (10.9%)", "50 (17%)", "48 (16.3%)", "49 (16.7%)", "81 (27.6%)", "34 (11.6%)", "6 (2.0%)",
    "", "154 (51%)", "144 (48%)", "1 (0%)",
    "", "251 (84%)", "23 (8%)", "11 (4%)", "10 (3%)", "5 (2%)",
    "", "154 (51%)", "104 (35%)", "30 (10%)", "8 (3%)", "4 (1%)",
    "", "147 (49%)", "64 (21%)", "46 (15%)", "20 (7%)", "18 (6%)", "5 (2%)",
    "", "130 (43%)", "62 (21%)", "30 (10%)", "31 (10%)", "17 (6%)", "18 (6%)",
    "9 (3%)", "3 (1%)",
    "Mean (SD)", "3.4 (0.8)", "2.1 (1.1)", "3.3 (1.3)", "2.7 (1.0)", 
    "2.2 (1.2)", "2.3 (1.0)", "1.9 (0.9)", "17.8 (4.8)"
  )
)
```
```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-demographic
#| tbl-cap: Summary of demographic information collected in the OPUF

# Create table
kable(demographic_data, "latex", booktabs = TRUE, col.names = c("Participant Characteristics (N=300)", "N (%)"), align = c("l", "r")) %>%
  kable_styling(full_width = TRUE, latex_options = c("scale_down"))
# , align = c("l", "r"), escape = FALSE) %>%
#   kable_styling(full_width = FALSE, position = "center") %>%
#   column_spec(1, bold = TRUE) %>%
#   add_header_above(c("Participant Characteristics (N=300)" = 1, "N (%)" = 1))
```


```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# Initialize the level_tab matrix
level_tab <- matrix(NA, nrow = 21, ncol = 5)
level_tab2 <- matrix(NA, nrow = 28, ncol = 5)

# List of categories
categories <- c("tired", "walk", "sports", "concentration", "embarrassment", "unhappiness", "treat")

# Fill the matrix using loops
row_index <- 1
for (category in categories) {
  for (i in 1:3) {
    level_tab[row_index, ] <- c(c("Almost never", "Sometimes", "Often")[i], calculate_stats(data[[paste0("opuf_levelRatings_", category, "_", i)]], 1))
    row_index <- row_index + 1
  }
}

level_tab2[1,] <- c("Tired", "" , "", "", "")
level_tab2[1,] <- cell_spec(level_tab2[1,], bold = TRUE) # Bold second row, column A
level_tab2[2,] <- level_tab[1,]
level_tab2[3,] <- level_tab[2,]
level_tab2[4,] <- level_tab[3,]
level_tab2[5,] <- c("Walking", "" , "", "", "")
level_tab2[5,] <- cell_spec(level_tab2[5,], bold = TRUE) # Bold third row, column B
level_tab2[6,] <- level_tab[4,]
level_tab2[7,] <- level_tab[5,]
level_tab2[8,] <- level_tab[6,]
level_tab2[9,] <- c("Sports", "" , "", "", "")
level_tab2[9,] <- cell_spec(level_tab2[9,], bold = TRUE) # Bold third row, column B
level_tab2[10,] <- level_tab[7,]
level_tab2[11,] <- level_tab[8,]
level_tab2[12,] <- level_tab[9,]
level_tab2[13,] <- c("Concentration", "" , "", "", "")
level_tab2[13,] <- cell_spec(level_tab2[13,], bold = TRUE) # Bold third row, column B
level_tab2[14,] <- level_tab[10,]
level_tab2[15,] <- level_tab[11,]
level_tab2[16,] <- level_tab[12,]
level_tab2[17,] <- c("Embarrassment", "" , "", "", "")
level_tab2[17,] <- cell_spec(level_tab2[17,], bold = TRUE) # Bold third row, column B
level_tab2[18,] <- level_tab[13,]
level_tab2[19,] <- level_tab[14,]
level_tab2[20,] <- level_tab[15,]
level_tab2[21,] <- c("Unhappiness", "" , "", "", "")
level_tab2[21,] <- cell_spec(level_tab2[21,], bold = TRUE) # Bold third row, column B
level_tab2[22,] <- level_tab[16,]
level_tab2[23,] <- level_tab[17,]
level_tab2[24,] <- level_tab[18,]
level_tab2[25,] <- c("Treated differently", "" , "", "", "")
level_tab2[25,] <- cell_spec(level_tab2[25,], bold = TRUE) # Bold third row, column B
level_tab2[26,] <- level_tab[19,]
level_tab2[27,] <- level_tab[20,]
level_tab2[28,] <- level_tab[21,]

colnames(level_tab2) <- colnames(time_tab)
```
```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-level
#| tbl-cap: Summary of OPUF level ratings by attribute
kable(level_tab2, digits = 3, align = c("l", "r", "r", "r", "r"))
```

## Attribute weights
Summary statistics of attribute weightings are presented in @tbl-attribute. On average, Tiredness (76.5) and Unhappiness (70) were considered to be more important to participants than Embarrassment (40.1) and Sports (42.3). There was less variability in attribute weighting responses to Tiredness than responses to Treated differently or Embarrassment. @fig-rai illustrates the relative attribute importance (RAI) among WAItE attributes.     



```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# attribute weighting table
attribute_tab <- matrix(NA, nrow = 14, ncol = 5)
attribute_tab[1,] <- c("Tired", calculate_stats(data$opuf_swingWeights_tired, 1))
attribute_tab[2,] <- c("Walking", calculate_stats(data$opuf_swingWeights_walk, 1))
attribute_tab[3,] <- c("Sports", calculate_stats(data$opuf_swingWeights_sports, 1))
attribute_tab[4,] <- c("Concentration", calculate_stats(data$opuf_swingWeights_concentration, 1))
attribute_tab[5,] <- c("Embarrassment", calculate_stats(data$opuf_swingWeights_embarrassment, 1))
attribute_tab[6,] <- c("Unhappiness", calculate_stats(data$opuf_swingWeights_unhappiness, 1))
attribute_tab[7,] <- c("Treated differently", calculate_stats(data$opuf_swingWeights_treat, 1))
attribute_tab[8,] <- c("Anchoring", "", "", "", "")
attribute_tab[8,] <- cell_spec(attribute_tab[8,], bold = TRUE) 


# fix anchorpoint data
data$preferred_pits[data$opuf_anchorPoint==""] <- NA
data$preferred_pits[data$opuf_anchorPoint=="dead"] <- 1
data$preferred_pits[data$opuf_anchorPoint=="pits"] <- 0
preferred_pits <- data$preferred_pits[!is.na(data$preferred_pits)]

pits_vas <- ifelse(data$opuf_anchorPoint=="dead", data$opuf_anchorVal, NA)
pits_vas <- pits_vas[!is.na(pits_vas)]
dead_vas <- ifelse(data$opuf_anchorPoint=="pits", data$opuf_anchorVal, NA)
dead_vas <- dead_vas[!is.na(dead_vas)]
opuf_pitsUtility <- data$opuf_pitsUtility
opuf_pitsUtility <- opuf_pitsUtility[!is.na(opuf_pitsUtility)]
censored_opuf_pitsUtility <- ifelse(opuf_pitsUtility < -1, -1, opuf_pitsUtility) 


attribute_tab[9 ,] <- c("PITS preferred to death", calculate_stats(preferred_pits, 1))
attribute_tab[10 ,] <- c("PITS-VAS", calculate_stats(pits_vas, 1))
attribute_tab[11,] <- c("Dead-VAS", calculate_stats(dead_vas, 1))
attribute_tab[12,] <- c("PITS VAS uncensored", calculate_stats(opuf_pitsUtility, 3))
attribute_tab[13,] <- c("PITS VAS censored", calculate_stats(censored_opuf_pitsUtility, 3))

attribute_tab[14,] <- c("PITS Utility Value", calculate_stats(data$PITS, 3))

colnames(attribute_tab) <- colnames(time_tab)
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-attribute
#| tbl-cap: Summary of OPUF attribute weights and anchoring responses
kable(attribute_tab, digits = 3, align = c("l", "r", "r", "r", "r"))
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
rai_vector <- c(76.513, 65.53, 42.32, 67.897, 40.143, 69.997, 52.093)
rai_labels <- c("Tired", "Walking", "Sports", "Concentration", "Embarrassment", "Unhappiness", "Treated differently")
rai_data <- data.frame(
  Category = rai_labels,  # Categories for the x-axis
  Value = rai_vector      # Values for the y-axis
)

rai_data$Category <- factor(rai_data$Category, levels = unique(rai_data$Category))
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
#| label: fig-rai
#| fig-cap: Relative attribute importance

ggplot(rai_data, aes(x = Category, y = Value, fill = Category)) +  # Categories on the x-axis
  geom_col() +                                                  # Bar chart with the provided values
  scale_fill_viridis(discrete = TRUE) +                          # Apply viridis colors
  labs(x = "Attribute", y = "Attribute weighting", fill = "Attribute") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 22.5, hjust = 1))       # Rotate x-axis labels by 45 degrees

```

## Anchoring
The majority of respondents in the sample preferred the WAItE PITS state to being dead (87\%). Therefore, 13\% of participants answered the dead-VAS and 87\% answered the PITS-VAS. A proportion of participants did not answer the anchoring task (1.67\%). After winsorizing extreme values (top and bottom 0.1\%) [@2003ApplyingTechniques] and conducting multiple imputation by chained equations on the missing values, the mean (SD) and median (IQR) PITS utility value was 0.282 (1.456) and 0.5 (0.6). The distribution of WAItE PITS utility values (after winsorizing and imputation) is presented in @fig-hist.

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
hist <- filter(data, PITS>-5.01)
hist <- ggplot(hist, aes(x = PITS, fill = PITS < -0.05)) +
  geom_histogram(binwidth = 0.15, color = "black", alpha = 0.9) +
  scale_fill_manual(values = c("FALSE" = "#f2db0d", "TRUE" = "#625e5e"), 
                    labels = c("FALSE" = "PITS-VAS", "TRUE" = "Dead-VAS"),
                    name = "Anchoring task") +
  labs(x = "WAItE PITS utility",
       y = "Frequency") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.2, face = "bold", size = 14),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    legend.text = element_text(size = 12)
  ) +
  theme(
    axis.title.x = element_text(size = 14, margin = margin(t = 10, r = 0, b = 0, l = 0)),
    axis.title.y = element_text(size = 14, margin = margin(t = 0, r = 10, b = 0, l = 0)),
    
  )
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| dev: "png"
#| label: fig-hist
#| fig-cap: Distribution of PITS utility values
#| fig.height: 3
hist
```

\newpage

## Social utility function estimation
Personal utility functions were estimated individually for each participant in our analysis sample via methods outlined in @sec-OPUF_methods. After this, individual PUFs were aggregated into a group utility function and anchored using the group PITS utility value (0.282) to give the social utility function. Descriptive statistics from the social utility function are presented in @tbl-suf whereby the mean values can be used to estimate utility values for WAItE health states. Confidence intervals were estimated from bootstrap resampling with 10,000 iterations. 

@fig-sufplain presents the mean social utility function (thick line) alongside individual personal utility functions (thin lines) for a selection of 100 WAItE health states ordered from high to low utility according to the social preference. Deviations of individual utility functions from the social preference illustrate the heterogeneity of preference within our analysis sample. Individual personal utility functions shown in @fig-sufplain are anchored using individual PITS utility values rather than the social PITS utility value.   

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}
# Bootstrapping 
#############################################################################
#setseed
#############################################################################
#setseed
set.seed(1998)
# Set the number of bootstrap iterations
n_iterations <- 10000

# Initialize a list to store the mean matrices from each bootstrap iteration
bootstrap_means <- list()
bootstrap_medians <- list()

if (method == "median") {
  for (n in 1:n_iterations) {
    # Sample with replacement from the results_list
    sample_indices <- sample(1:length(results_list), replace = TRUE)
    bootstrap_sample <- results_list[sample_indices]

    # Initialize a matrix to store the sum of the bootstrap sample matrices
    bootstrap_median_matrix <- matrix(0, nrow = 7, ncol = 4)  
    #TODO: Above code was previously nrow = 7, ncol = 4??? Figure out why
    attributes <- c("tired", "walking", "sports", "concentration", "embarrassed", "unhappiness", "treat")
    levels <- 2:5

    # Populate medians for each attribute and level in a single matrix
    median_matrix <- do.call(cbind, lapply(seq_along(attributes), function(j) {
      medians <- sapply(levels, function(lvl) median(sapply(bootstrap_sample, function(mat) mat[lvl, j])))
      c(0, medians)  # Add 0 at the start for each attribute
    }))

    # bootstrap_median_matrices <- c(bootstrap_median_matrices, median_matrix) 
    #
    # # Calculate the median matrix for this bootstrap sample
    # bootstrap_median_matrix <- bootstrap_sum_matrix / length(bootstrap_sample)
    # Anchor it
    bootstrap_median_matrix <- median_matrix * (1-anchor) 

    # Store the bootstrap mean matrix
    bootstrap_medians[[n]] <- bootstrap_median_matrix
  }
}

if (method == "mean"){
  # Bootstrap loop
  for (n in 1:n_iterations) {
    # Sample with replacement from the results_list
    sample_indices <- sample(1:length(results_list), replace = TRUE)
    bootstrap_sample <- results_list[sample_indices]

    # Initialize a matrix to store the sum of the bootstrap sample matrices
    bootstrap_sum_matrix <- matrix(0, nrow = 7, ncol = 4)  
    #TODO: Above code was previously nrow = 7, ncol = 4??? Figure out why

    # Sum all matrices in the bootstrap sample
    for (m in bootstrap_sample) {
      m <- m[-1,]
      m <- t(m)
      bootstrap_sum_matrix <- bootstrap_sum_matrix + m
    }

    # Calculate the mean matrix for this bootstrap sample
    bootstrap_mean_matrix <- bootstrap_sum_matrix / length(bootstrap_sample)
    # Anchor it
    bootstrap_mean_matrix <- bootstrap_mean_matrix * (1-anchor) 

    # Store the bootstrap mean matrix
    bootstrap_means[[n]] <- bootstrap_mean_matrix
  }
}
# Convert the list of bootstrap mean matrices into a 3D array
bootstrap_array <- simplify2array(bootstrap_means)
if (method == "median"){
  bootstrap_array <- simplify2array(bootstrap_means)
}
# Initialize matrices to store the required statistics
mean_matrix <- apply(bootstrap_array, c(1, 2), mean)
median_matrix <- apply(bootstrap_array, c(1, 2), median)
q1_matrix <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.25)
q3_matrix <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.75)
min_matrix <- apply(bootstrap_array, c(1, 2), min)
max_matrix <- apply(bootstrap_array, c(1, 2), max)

# Updated matrix estimates so that the median,quartiles, min and max aren't from the bootstrapping
results_list_df <- results_list_df * (1 - anchor)
median_matrix <- t(matrix(sapply(results_list_df, median), nrow = 5, ncol = 7, byrow=F))
q1_matrix <- t(matrix(sapply(results_list_df, function(x) quantile(x, probs = 0.25)), nrow = 5, ncol = 7, byrow = F))
q3_matrix <- t(matrix(sapply(results_list_df, function(x) quantile(x, probs = 0.75)), nrow = 5, ncol = 7, byrow = F))
min_matrix <- t(matrix(sapply(results_list_df, min), nrow = 5, ncol = 7, byrow=F))
max_matrix <- t(matrix(sapply(results_list_df, max), nrow = 5, ncol = 7, byrow=F))

median_matrix <- median_matrix[, -1]
q1_matrix <- q1_matrix[, -1]
q3_matrix <- q3_matrix[, -1]
min_matrix <- min_matrix[, -1]
max_matrix <- max_matrix[, -1]

# Calculate 95% confidence intervals
ci_lower <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.025)
ci_upper <- apply(bootstrap_array, c(1, 2), quantile, probs = 0.975)

# Initialize an empty list to store each row of the final table
final_table <- list()

# Define the attribute names and the levels
attributes <- c("tired", "walk", "sports", "concentrate", "embarrassment", "unhappiness", "treated differently")
levels <- c("almost never", "sometimes", "often", "always")

# Iterate through the rows and columns of the matrices
for (i in 1:nrow(mean_matrix)) {
  for (j in 1:ncol(mean_matrix)) {
    row_label <- paste0(attributes[i], ", ", levels[j])
    mean_ci <- paste0(format(round(mean_matrix[i, j], 3), nsmall = 3), " (", format(round(ci_lower[i, j], 3), nsmall = 3), "; ", format(round(ci_upper[i, j], 3), nsmall = 3), ")")
    median_q1_q3 <- paste0(format(round(median_matrix[i, j], 3), nsmall = 3), " (", format(round(q1_matrix[i, j], 3), nsmall = 3), "; ", format(round(q3_matrix[i, j], 3), nsmall = 3), ")")
    min_val <- round(min_matrix[i, j], 3)
    max_val <- format(round(max_matrix[i, j], 3), nsmall = 3)
    
    final_table[[length(final_table) + 1]] <- c(row_label, mean_ci, median_q1_q3, min_val, max_val)
  }
}

# Convert the final_table list to a data frame
final_df <- as.data.frame(do.call(rbind, final_table), stringsAsFactors = FALSE)
final_df2 <- data.frame(matrix(NA, nrow = 35, ncol = 5))
colnames(final_df2) <- c("Attribute Level", "Mean (95% CI)", "Median (Q1; Q3)", "Min", "Max")

final_df2[1 ,] <- c("Tired", "" , "", "", "")
final_df2[1,] <- cell_spec(final_df2[1,], bold = TRUE) # Bold second row, column A
final_df2[2 ,] <- final_df[1 ,]
final_df2[3 ,] <- final_df[2 ,]
final_df2[4 ,] <- final_df[3 ,]
final_df2[5 ,] <- final_df[4 ,]
final_df2[2 ,1] <- "Almost never"
final_df2[3 ,1] <- "Sometimes"
final_df2[4 ,1] <- "Often"
final_df2[5 ,1] <- "Always"

final_df2[6 ,] <- c("Walking", "" , "", "", "")
final_df2[6,] <- cell_spec(final_df2[6,], bold = TRUE) # Bold second row, column A
final_df2[7 ,] <- final_df[5 ,]
final_df2[8 ,] <- final_df[6 ,]
final_df2[9 ,] <- final_df[7 ,]
final_df2[10,] <- final_df[8 ,]
final_df2[7 ,1] <- "Almost never"
final_df2[8 ,1] <- "Sometimes"
final_df2[9 ,1] <- "Often"
final_df2[10 ,1] <- "Always"

final_df2[11 ,] <- c("Sports", "" , "", "", "")
final_df2[11,] <- cell_spec(final_df2[11,], bold = TRUE) # Bold second row, column A
final_df2[12 ,] <- final_df[9 ,]
final_df2[13 ,] <- final_df[10 ,]
final_df2[14 ,] <- final_df[11 ,]
final_df2[15 ,] <- final_df[12 ,]
final_df2[12 ,1] <- "Almost never"
final_df2[13 ,1] <- "Sometimes"
final_df2[14 ,1] <- "Often"
final_df2[15 ,1] <- "Always"

final_df2[16,] <- c("Concentration", "" , "", "", "")
final_df2[16,] <- cell_spec(final_df2[16,], bold = TRUE) # Bold second row, column A
final_df2[17,] <- final_df[13,]
final_df2[18,] <- final_df[14,]
final_df2[19,] <- final_df[15,]
final_df2[20,] <- final_df[16,]
final_df2[17 ,1] <- "Almost never"
final_df2[18 ,1] <- "Sometimes"
final_df2[19 ,1] <- "Often"
final_df2[20 ,1] <- "Always"

final_df2[21,] <- c("Embarrassment", "" , "", "", "")
final_df2[21,] <- cell_spec(final_df2[21,], bold = TRUE) # Bold second row, column A
final_df2[22,] <- final_df[17,]
final_df2[23,] <- final_df[18,]
final_df2[24,] <- final_df[19,]
final_df2[25,] <- final_df[20,]
final_df2[22 ,1] <- "Almost never"
final_df2[23 ,1] <- "Sometimes"
final_df2[24 ,1] <- "Often"
final_df2[25 ,1] <- "Always"

final_df2[26,] <- c("Unhappiness", "" , "", "", "")
final_df2[26,] <- cell_spec(final_df2[26,], bold = TRUE) # Bold second row, column A
final_df2[27,] <- final_df[21,]
final_df2[28,] <- final_df[22,]
final_df2[29,] <- final_df[23,]
final_df2[30,] <- final_df[24,]
final_df2[27 ,1] <- "Almost never"
final_df2[28 ,1] <- "Sometimes"
final_df2[29 ,1] <- "Often"
final_df2[30 ,1] <- "Always"

final_df2[31,] <- c("Treated differently", "" , "", "", "")
final_df2[31,] <- cell_spec(final_df2[31,], bold = TRUE) # Bold second row, column A
final_df2[32,] <- final_df[25,]
final_df2[33,] <- final_df[26,]
final_df2[34,] <- final_df[27,]
final_df2[35,] <- final_df[28,]
final_df2[32 ,1] <- "Almost never"
final_df2[33 ,1] <- "Sometimes"
final_df2[34 ,1] <- "Often"
final_df2[35 ,1] <- "Always"

#TODO: IMPORTANT resolve the medians and Qs to be actual not bootstrapped



```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-suf
#| tbl-cap: Social utility function based on 300 PUFs
kable(final_df2, align = c("l", "r", "r", "r", "r")) 
```

## Preference heterogeneity
After estimating individual PUFs for all participants, pairwise EUD was estimated between all participants. This yielded a [300 $\times$ 300] distance matrix with 44,850 unique pairwise comparisons. The mean (SD) and median (IQR) EUD were `r round(eud_summary[1], 2)` (`r round(eud_summary[2], 2)`) and  `r round(eud_summary[3], 2)` (`r round(eud_summary[4], 2)`; `r round(eud_summary[5], 2)`). The highest and lowest observed EUD were `r round(max(distance_vector), 2)` and `r round(min(distance_vector), 2)`. @fig-eud illustrates the relationship between EUD and WAItE health states. EUD tends to increase as WAItE health states worsen. That is, as the severity of WAItE health states increases, the more heterogeneous preferences become among our sample. 


```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| dev: "png"
#| fig.height: 3
#| label: fig-sufplain
#| fig-cap: Social and individual utility functions
plain_chart
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| dev: "png"
#| fig.height: 3.5
#| label: fig-eud
#| fig-cap: Social and individual utility functions coloured by EUD
eud_chart
```

## PERMANOVA
@tbl-permanova presents the PERMANOVA model results. Presented are within‐group sum‐of‐squares (SS$_W$) for each group individually and for all groups combined, and the corresponding R$^2$, pseudo $F$, and $p$ values. Preference heterogeneity was significantly affected by age ($p$ = 0.03), though the amount of variability in preferences that could be explained by age was relatively small (R$^2$ = 5.7\%). @fig-age presents the difference in preferences between different age groups. Generally, as age increases, health state utility values for each given WAItE health state are higher. That is, younger populations tend to place more disutility on WAItE health problems than older populations. While weight status was not significantly related to preference heterogeneity according to the PERMANOVA model, given the WAItE is a weight-specific measure, it was informative to explore the relationship between preferences and weight status. Though not statistically significant, we can observe a difference in preferences between normal weight and overweight individuals in @fig-weight. For a given WAItE health state, overweight individuals in our sample placed less disutility on that state than did normal weight individuals. 


```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-permanova
#| tbl-cap: Results of PERMANOVA – testing for differences in WAItE health state preferences between group characteristics
permanova_main <- as.data.frame(permanova_main)
rownames(permanova_main) <- c("Age", "Weight status", "Education", "Occupation", "Gender", "Ethnicity", "Residual", "Total")
options(knitr.kable.NA = '')
kable(permanova_main, col.names = c("Variable", "df", "$SS_W$", "$R^2$", "F", "Pr(>F)"), digits = 3)
```


## Sensitivity analysis
### Attribute weighting and level rating preference heterogeneity
EUD2 was estimated for each pairwise comparison of individuals in our study. The mean (SD) and median (IQR) EUD were 34.30 (13.82) and 32.25 (24.54; 41.27). Results from the PERMANOVA2 analysis are presented in @tbl-permanova2. After exclusion of individual variation in anchoring responses, weight status and age had a significant impact upon heterogeneity within our sample; though the amount of heterogeneity that was explained by these variables was fairly small (4.9\%). 


```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-permanova2
#| tbl-cap: PERMANOVA2 – testing for differences in level rating and attribute weighting preferences between group characteristics
permanova2 <- as.data.frame(permanova2)
rownames(permanova2) <- c("Age", "Weight status", "Education", "Occupation", "Gender", "Ethnicity", "Residual", "Total")
options(knitr.kable.NA = '')
kable(permanova2, col.names = c("Variable", "df", "$SS_W$", "$R^2$", "F", "Pr(>F)"), digits = 3)
```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| dev: "png"
#| label: fig-age
#| fig-cap: Social and individual utility functions grouped by age status
age_chart
```
### Anchoring preference heterogeneity
A multivariate Gamma GLM model was estimated to explore preference heterogeneity in anchoring values (presented in @tbl-glmpits). Demographic characteristics were regressed on PITS utility values to examine how demographic information was related to anchoring values. Age, had a significant impact on anchoring preference heterogeneity ($p$ = `r round(summary(gamma_multivar_model)$coefficients[2,4], 3)`), though the point estimate indicated a relatively small effect size. 
```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-glmpits
#| tbl-cap: Multivariate Gamma GLM Model – exploring the relationship between PITS utility value and demographic characteristics
glm <- summary(gamma_multivar_model)$coefficients
rownames(glm) <- c("Intercept", "Age", "Education", "Occupation", "Gender", "Ethnicity")
kable(glm, digits = 3, col.names = c("Variable", "$\\beta$", "$SE$", "$t$", "Pr(>|t|)"))
# include footnotes with AIC(gamma_multivar_model BIC(gamma_multivar_model)
```
# Discussion
This study is the first time that the OPUF has been used to estimate health state utility values for the WAItE. We obtained a representative sample of high quality data from Prolific, a survey company known for their high quality respondents [@Peer2022DataResearch]. Our average attribute weightings and implied ordering were similar to those exhibited in Robinson et al. (2024) @Robinson2024AUKValue. 

Anchoring of the WAItE PITS state was a difficult procedure that required a number of methodological decisions. We decided to use uncensored responses to the Dead-VAS task which meant that data from one respondent (-99) skewed the mean PITS utility value quite substantially. To mitigate the impact of extreme values on the mean, we conducted winsorization of values lying in the outer 0.1\% of the distribution. This practice, while effective at limiting the influence of extreme values on the mean, could understate the genuine variability in the data. However, winsorization would likely have had less of a distributional effect than exclusion altogether.

The social utility function elicited through this study, and underlying utility value set, present monotonic preferences which behave as one would have expected ex-ante (based on qualitative piloting work). Tiredness and Unhappiness were considered the most important attributes while Embarrassment and Sports the least important. As well as concurring with previous qualitative work, this is also in accordance with previous valuation work done with the WAItE @Robinson2024AUKValue. Prior valuation work, which used a DCE to elicit preferences, yielded latent coefficients which violated the rational choice axiom of monotonicity. In the OPUF, monotonicity is essentially forced through the choice architecture of the level rating and the additional prompt to reconsider responses that are not monotonic. Forced monotonicity, in this context, could be problematic for eliciting unbiased preferences if preferences for certain health states are truly not monotonic. For example, prior qualitative work has suggested that "I almost never get tired" might be preferable to "I never get tired" in some circumstances where respondents are thinking about experiencing insomnia and sleep quality. This being said, the WAItE descriptive system was designed to be a monotonic descriptive system, validated using Rasch analysis, and so having a monotonic utility value set makes logical sense. 

Preferences elicited through this study were considerably heterogeneous. This can be understood through the mean EUD value (47.6) but also illustrated in @fig-sufplain through the deviations of individual PUFs from the social utility function. Following on from prior work [@Schneider2024ExploringLevel], we estimated EUD by calculating a distance matrix between each pairwise comparison of individual value sets for all 78125 WAItE health states. The implication of estimating distance (preference heterogeneity) by using individual value sets allows for much of the preference heterogeneity that exists to be composed of differences in individual anchoring values (PITS state responses) rather than differences in level ratings and attribute weightings. This methodological decision, ultimately, results in the majority of EUD being composed of differences in anchoring values and this finding is important to acknowledge. Anchoring differences are important to present and explore, though in this preference heterogeneity analysis could be drowning out the heterogeneity in level ratings and attribute weighting. An example of this can be shown through the age preference heterogeneity in @fig-age and @tbl-glmpits. Preference heterogeneity is evident between individuals above and below age 35 and if we consider the mean PITS values for those two subgroups (age $<$ 35 = -0.281; age $>$ 34 = 0.487) we can see that a clear difference in anchoring responses is evident. 

A methodological exploration was conducted as a sensitivity analysis to limit the influence that anchoring variation has on the overall preference heterogeneity. We considered this to be a strength of the research as it offers a new approach to decompose preference heterogeneity into anchoring variation and the difference in level ratings and attribute weightings. After exclusion of individual variation in anchoring responses, weight status and age were found to have a significant impact on preference heterogeneity within our sample; though the amount of variation that could be explained was limited. Preference heterogeneity between those of normal weight and those who were overweight is illustrated in @fig-weight.

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| dev: "png"
#| label: fig-weight
#| fig-cap: Social and individual utility functions grouped by weight status
weight_chart
```
This method of estimating preference heterogeneity should not be considered the gold standard, as only part of the variation in preferences is explored here. It can however be considered an additional option for future researchers that wish to isolate the effect of anchoring responses on overall preference heterogeneity. It is also, to our knowledge, the first time preference heterogeneity has been decomposed in this way with the OPUF. 

The value set estimated here offers an alternative choice of preference values to the existing value sets estimated using DCE (shown in @tbl-WAItEvalsets). When comparing the anchored coefficients between value sets, one of the key areas of divergence is where levels have been collapsed in the DCE value set. In the OPUF, "I almost never get tired" is given 0.029 compared to 0.064 in the DCE due to collapsing levels. Generally the difference between coefficients that have not been 'collapsed' between the value sets is small suggesting that there is comparability to an extent between the value sets. Anchoring values were broadly similar between studies too. The mean PITS utility values between studies were broadly comparable with a maximum range of 0.059. Interestingly, the EQ-VAS @webb2020transforming anchoring task mean (0.289) was notably similar to the OPUF VAS anchoring task mean (0.282) again supporting the use of VAS for elicitation of PITS utility values. 

```{r, echo = F, message = FALSE, warning = FALSE, results = "hide"}

v_anchored <- format(round(as.vector(anchored_matrix[2:5,]), 3), nsmall = 3)
for(i in c(31, 26, 21, 16, 11, 6, 1)){
  dcetto_matrix <- dcetto_matrix[-i]
  dcevas_matrix <- dcevas_matrix[-i]
}
v_dcetto <- dcetto_matrix
v_dcevas <- dcevas_matrix


attribute_names <- c("Tired", "Walking", "Sports", "Concentration", "Embarrassment", "Unhappiness", "Treated differently")

# Level labels
level_labels <- c("Almost never", "Sometimes", "Often", "Always")

# Create a placeholder data frame for the final table
tab_valuesets <- data.frame(
  `Attribute level` = character(),
  OPUF = character(),
  `DCE-TTO` = character(),
  `DCE-VAS` = character()
)

# Populate the table by interleaving attributes and levels
for (i in seq_along(attribute_names)) {
  # Add the attribute name as a new row
  tab_valuesets <- rbind(tab_valuesets, data.frame(
    `Attribute level` = attribute_names[i],
    OPUF = "",
    `DCE-TTO` = "",
    `DCE-VAS` = ""
  ))
  
  # Add the levels for the current attribute
  tab_valuesets <- rbind(tab_valuesets, data.frame(
    `Attribute level` = level_labels,
    OPUF = format(v_anchored[(4 * (i - 1) + 1):(4 * i)], nsmall = 3),
    `DCE-TTO` = format(v_dcetto[(4 * (i - 1) + 1):(4 * i)], nsmall = 3),
    `DCE-VAS` = format(v_dcevas[(4 * (i - 1) + 1):(4 * i)], nsmall = 3)
  ))
}

tab_valuesets[1, ] <- cell_spec(tab_valuesets[1, ], bold = TRUE) 
tab_valuesets[6, ] <- cell_spec(tab_valuesets[6, ], bold = TRUE) 
tab_valuesets[11,] <- cell_spec(tab_valuesets[11,], bold = TRUE) 
tab_valuesets[16,] <- cell_spec(tab_valuesets[16,], bold = TRUE) 
tab_valuesets[21,] <- cell_spec(tab_valuesets[21,], bold = TRUE) 
tab_valuesets[26,] <- cell_spec(tab_valuesets[26,], bold = TRUE) 
tab_valuesets[31,] <- cell_spec(tab_valuesets[31,], bold = TRUE) 
# Print the table using kable

```

```{r, echo = F, message = FALSE, warning = FALSE, results = "show"}
#| label: tbl-WAItEvalsets
#| tbl-cap: Comparison of WAItE utility value sets
kable(tab_valuesets, digits = 3, col.names = c("Attribute Level", "OPUF", "DCE-TTO", "DCE-VAS"), align = c("l", "r", "r", "r"))
```

::: {.content-visible when-format="html"}
## Appendix {.appendix}

### Derivation of EUD2 {#sec-appendix1}
Matrices $\tilde{M}_{1ij}$ and $\tilde{M}_{2ij}$ denote latent coefficient matrices from individual 1 and 2, for attributes $i$ and levels $j$, from the analysis sample. Matrices $\tilde{M}_{1ij}$ and $\tilde{M}_{2ij}$ were then anchored using the social PITS utility value 0.282 (shown in @eq-anchoring-matrices). 

$$
\tilde{M}_{1ij} =  
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.03 & 0.02 & 0.01 & 0.01 & 0.02 & 0.03 & 0.05 \\
0.11 & 0.07 & 0.05 & 0.03 & 0.07 & 0.05 & 0.11 \\
0.15 & 0.09 & 0.07 & 0.04 & 0.12 & 0.08 & 0.19 \\
0.17 & 0.11 & 0.08 & 0.10 & 0.14 & 0.10 & 0.30
\end{bmatrix}
$$ {#eq-coef-1}

$$
\tilde{M}_{2ij} =  
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0.05 & 0.02 & 0.01 & 0.01 & 0.02 & 0.03 & 0.03 \\
0.15 & 0.11 & 0.03 & 0.05 & 0.09 & 0.04 & 0.09 \\
0.18 & 0.13 & 0.05 & 0.06 & 0.14 & 0.06 & 0.16 \\
0.21 & 0.15 & 0.06 & 0.11 & 0.17 & 0.08 & 0.23
\end{bmatrix}
$$ {#eq-coef-2}

$$
    \tilde{V}_{1ij} = \tilde{M}_{1ij} \cdot (1-0.282); \quad
    \tilde{V}_{2ij} = \tilde{M}_{2ij} \cdot (1-0.282)
$$ {#eq-anchoring-matrices}

$$
\tilde{V}_{1ij} =  
\begin{bmatrix}
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
0.02 & 0.01 & 0.01 & 0.01 & 0.01 & 0.02 & 0.04 \\
0.08 & 0.05 & 0.04 & 0.02 & 0.05 & 0.04 & 0.08 \\
0.11 & 0.06 & 0.05 & 0.03 & 0.09 & 0.06 & 0.14 \\
0.12 & 0.08 & 0.06 & 0.07 & 0.1 & 0.07 & 0.22
\end{bmatrix}
$$ {#eq-vcoeff}

$$
\tilde{V}_{2ij} =  
\begin{bmatrix}
0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\
0.04 & 0.01 & 0.01 & 0.01 & 0.01 & 0.02 & 0.02 \\
0.11 & 0.08 & 0.02 & 0.04 & 0.06 & 0.03 & 0.06 \\
0.13 & 0.09 & 0.04 & 0.04 & 0.10 & 0.04 & 0.11 \\
0.15 & 0.11 & 0.04 & 0.08 & 0.12 & 0.06 & 0.17
\end{bmatrix}
$$ {#eq-vcoeff2}

Once anchored coefficient matrices @eq-vcoeff and @eq-vcoeff2 are estimated, a complete profile of health state utility values for individual 1 and 2 are estimated for all 78,125 unique health states described by the WAItE. This yields a [78125 $\times$ 1] vector for each individual ranging from (1, 0.282) (shown in @eq-healthstate-utilities}). 

$$
\begin{aligned}  
\tilde{U}_{1,s} &=  \{1, 0.98, 0.96, ..., 0.282\}; \quad \tilde{U}_{2,s} =  \{1, 0.97, 0.95, ..., 0.282\} \\
&\backepsilon \quad \quad s = \{1111111, 2111111, ..., 5555555\}
\end{aligned}
$$ {#eq-healthstate-utilities}

To estimate euclidean distance between the two health state utility vectors, the square root of the sum of the squared differences between each element in the vector is calculated (shown in @eq-EUD, and populated for responses from individual 1 and 2 in @eq-pairwiseEUD2). 

$$
  \begin{aligned}
    d_{EUD2}(i,j) & =\sqrt{\sum_{}^{}(u_{i}(s_{1})-u_{j}(s_{1}))^{2}+ ... +(u_{i}(s_{78125})-u_{j}(s_{78125}))^{2}}\\
      & \backepsilon \quad \quad s = \{1111111, 2111111, ..., 5555555\}\\
  \end{aligned}
$$ {#eq-EUD2}

$$
d_{EUD2}(i,j) = \sqrt{\{(1-1)^2+(0.98-0.97)^2+(0.96-0.95)^2+ ... +(0.282-0.282)^2\}}
$$ {#eq-pairwiseEUD2}

Pairwise EUD2 was estimated for all possible combinations of individuals in our analysis sample. EUD2 was stored in a distance matrix of dimensions [300 $\times$ 300], where coordinates [3,7] represents the EUD2 between individual 3 and 7. The mean of the distance matrix provides the overall measure of disimilarity/heterogeneity within the analysis sample.  

:::
